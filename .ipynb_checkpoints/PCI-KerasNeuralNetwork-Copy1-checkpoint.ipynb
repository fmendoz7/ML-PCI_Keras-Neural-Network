{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminaries\n",
    "\n",
    "from __future__ import absolute_import, division, print_function  # Python 2/3 compatibility\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "from keras.models  import Sequential, K\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set \n",
    "file = \"pima-indians-diabetes.csv\"\n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv(file, names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(777, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>2</td>\n",
       "      <td>84.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.968</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>26.4</td>\n",
       "      <td>0.352</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>3</td>\n",
       "      <td>142.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.4</td>\n",
       "      <td>0.200</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>6</td>\n",
       "      <td>147.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.5</td>\n",
       "      <td>0.178</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>2</td>\n",
       "      <td>117.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>25.2</td>\n",
       "      <td>0.313</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "517              2                    84.0            50.0            23.0   \n",
       "722              0                   134.0            58.0            20.0   \n",
       "272              3                   142.0            80.0            15.0   \n",
       "651              6                   147.0            80.0             0.0   \n",
       "509              2                   117.0            90.0            19.0   \n",
       "\n",
       "     insulin   bmi  pedigree_function   age  has_diabetes  \n",
       "517     76.0  30.4              0.968  21.0           0.0  \n",
       "722    291.0  26.4              0.352  21.0           0.0  \n",
       "272      0.0  32.4              0.200  63.0           0.0  \n",
       "651      0.0  29.5              0.178  50.0           1.0  \n",
       "509     71.0  25.2              0.313  21.0           0.0  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values\n",
    "\n",
    "X = X[9:]\n",
    "y = y[9:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions.\n",
    "\n",
    "__Note:__ AUROC is a figure for comparing **false positive rate** to **true positive rate**. To know more about how to calculate AUROC refer to __[here](https://stats.stackexchange.com/questions/132777/what-does-auc-stand-for-and-what-is-it)__.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.766\n",
      "roc-auc is 0.826\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "\n",
    "# predict(X) -> Predict class for X.\n",
    "# predict_proba(X) -> Predict class probabilities for X.\n",
    "\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "# Below two results should be equal for big data sets.\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code will generate AUROC plot for the random forest prediction result.<br>\n",
    "The **Accuracy** in AUROC is measured by the area under the ROC curve. An area of 1 represents a perfect test; an area of .5 represents a worthless. <br>\n",
    "The x axis is the **False positive rate (FPR)** and the y axis is the **True positive rate (TPR)**. Check this __[Ref](http://gim.unmc.edu/dxtests/roc3.htm)__ for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## The StandardScaler assumes your data is normally distributed within each feature and will scale them such \n",
    "## that the distribution is now centred around 0, with a standard deviation of 1.\n",
    "\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential([\n",
    "    Dense(12, input_shape=(8,), activation=\"sigmoid\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Use the summary function. It is a nice tool to view the model you have created and count the parameters.\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "**ANSWER**: You have 121 parameters, 108 from the first hidden layer and then 13 from the output layer.\n",
    "The number of trainable parameters per layer is determined by ((shape of width of filter*shape of height filter+1)*number of filters)\n",
    "\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/200\n",
      "576/576 [==============================] - 0s 152us/step - loss: 0.6899 - accuracy: 0.5747 - val_loss: 0.6926 - val_accuracy: 0.5781\n",
      "Epoch 2/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6868 - accuracy: 0.5972 - val_loss: 0.6900 - val_accuracy: 0.5781\n",
      "Epoch 3/200\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6840 - accuracy: 0.6024 - val_loss: 0.6876 - val_accuracy: 0.5990\n",
      "Epoch 4/200\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.6814 - accuracy: 0.6215 - val_loss: 0.6855 - val_accuracy: 0.6146\n",
      "Epoch 5/200\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6790 - accuracy: 0.6215 - val_loss: 0.6834 - val_accuracy: 0.6198\n",
      "Epoch 6/200\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.6767 - accuracy: 0.6181 - val_loss: 0.6815 - val_accuracy: 0.6302\n",
      "Epoch 7/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6745 - accuracy: 0.6267 - val_loss: 0.6797 - val_accuracy: 0.6302\n",
      "Epoch 8/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6726 - accuracy: 0.6319 - val_loss: 0.6781 - val_accuracy: 0.6302\n",
      "Epoch 9/200\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6707 - accuracy: 0.6372 - val_loss: 0.6765 - val_accuracy: 0.6354\n",
      "Epoch 10/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6689 - accuracy: 0.6372 - val_loss: 0.6750 - val_accuracy: 0.6406\n",
      "Epoch 11/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6673 - accuracy: 0.6424 - val_loss: 0.6736 - val_accuracy: 0.6406\n",
      "Epoch 12/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6657 - accuracy: 0.6424 - val_loss: 0.6723 - val_accuracy: 0.6354\n",
      "Epoch 13/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6642 - accuracy: 0.6458 - val_loss: 0.6710 - val_accuracy: 0.6406\n",
      "Epoch 14/200\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.6628 - accuracy: 0.6476 - val_loss: 0.6698 - val_accuracy: 0.6406\n",
      "Epoch 15/200\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.6614 - accuracy: 0.6476 - val_loss: 0.6686 - val_accuracy: 0.6354\n",
      "Epoch 16/200\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.6601 - accuracy: 0.6476 - val_loss: 0.6675 - val_accuracy: 0.6354\n",
      "Epoch 17/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.6588 - accuracy: 0.6476 - val_loss: 0.6664 - val_accuracy: 0.6354\n",
      "Epoch 18/200\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.6576 - accuracy: 0.6476 - val_loss: 0.6654 - val_accuracy: 0.6354\n",
      "Epoch 19/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.6565 - accuracy: 0.6493 - val_loss: 0.6644 - val_accuracy: 0.6406\n",
      "Epoch 20/200\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6553 - accuracy: 0.6493 - val_loss: 0.6634 - val_accuracy: 0.6406\n",
      "Epoch 21/200\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.6542 - accuracy: 0.6493 - val_loss: 0.6625 - val_accuracy: 0.6406\n",
      "Epoch 22/200\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6532 - accuracy: 0.6493 - val_loss: 0.6615 - val_accuracy: 0.6406\n",
      "Epoch 23/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6522 - accuracy: 0.6493 - val_loss: 0.6606 - val_accuracy: 0.6406\n",
      "Epoch 24/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6512 - accuracy: 0.6493 - val_loss: 0.6597 - val_accuracy: 0.6406\n",
      "Epoch 25/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6502 - accuracy: 0.6493 - val_loss: 0.6589 - val_accuracy: 0.6406\n",
      "Epoch 26/200\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.6493 - accuracy: 0.6493 - val_loss: 0.6580 - val_accuracy: 0.6406\n",
      "Epoch 27/200\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6483 - accuracy: 0.6493 - val_loss: 0.6572 - val_accuracy: 0.6406\n",
      "Epoch 28/200\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.6475 - accuracy: 0.6493 - val_loss: 0.6564 - val_accuracy: 0.6406\n",
      "Epoch 29/200\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6466 - accuracy: 0.6493 - val_loss: 0.6556 - val_accuracy: 0.6406\n",
      "Epoch 30/200\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6457 - accuracy: 0.6493 - val_loss: 0.6548 - val_accuracy: 0.6406\n",
      "Epoch 31/200\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.6448 - accuracy: 0.6510 - val_loss: 0.6540 - val_accuracy: 0.6406\n",
      "Epoch 32/200\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.6440 - accuracy: 0.6510 - val_loss: 0.6532 - val_accuracy: 0.6406\n",
      "Epoch 33/200\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.6432 - accuracy: 0.6510 - val_loss: 0.6524 - val_accuracy: 0.6406\n",
      "Epoch 34/200\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6424 - accuracy: 0.6510 - val_loss: 0.6516 - val_accuracy: 0.6406\n",
      "Epoch 35/200\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6415 - accuracy: 0.6510 - val_loss: 0.6509 - val_accuracy: 0.6406\n",
      "Epoch 36/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6407 - accuracy: 0.6510 - val_loss: 0.6501 - val_accuracy: 0.6406\n",
      "Epoch 37/200\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6400 - accuracy: 0.6510 - val_loss: 0.6494 - val_accuracy: 0.6406\n",
      "Epoch 38/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6392 - accuracy: 0.6510 - val_loss: 0.6487 - val_accuracy: 0.6406\n",
      "Epoch 39/200\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6384 - accuracy: 0.6510 - val_loss: 0.6479 - val_accuracy: 0.6406\n",
      "Epoch 40/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6377 - accuracy: 0.6510 - val_loss: 0.6472 - val_accuracy: 0.6406\n",
      "Epoch 41/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6369 - accuracy: 0.6510 - val_loss: 0.6465 - val_accuracy: 0.6406\n",
      "Epoch 42/200\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6361 - accuracy: 0.6510 - val_loss: 0.6458 - val_accuracy: 0.6406\n",
      "Epoch 43/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6354 - accuracy: 0.6510 - val_loss: 0.6451 - val_accuracy: 0.6406\n",
      "Epoch 44/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.6347 - accuracy: 0.6510 - val_loss: 0.6443 - val_accuracy: 0.6406\n",
      "Epoch 45/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6339 - accuracy: 0.6510 - val_loss: 0.6436 - val_accuracy: 0.6406\n",
      "Epoch 46/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6332 - accuracy: 0.6510 - val_loss: 0.6429 - val_accuracy: 0.6406\n",
      "Epoch 47/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6325 - accuracy: 0.6510 - val_loss: 0.6423 - val_accuracy: 0.6406\n",
      "Epoch 48/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6318 - accuracy: 0.6510 - val_loss: 0.6416 - val_accuracy: 0.6406\n",
      "Epoch 49/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6311 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6406\n",
      "Epoch 50/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6304 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6406\n",
      "Epoch 51/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.6297 - accuracy: 0.6510 - val_loss: 0.6395 - val_accuracy: 0.6406\n",
      "Epoch 52/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6290 - accuracy: 0.6510 - val_loss: 0.6388 - val_accuracy: 0.6406\n",
      "Epoch 53/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6283 - accuracy: 0.6510 - val_loss: 0.6381 - val_accuracy: 0.6406\n",
      "Epoch 54/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6276 - accuracy: 0.6510 - val_loss: 0.6375 - val_accuracy: 0.6406\n",
      "Epoch 55/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6270 - accuracy: 0.6510 - val_loss: 0.6368 - val_accuracy: 0.6406\n",
      "Epoch 56/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6263 - accuracy: 0.6510 - val_loss: 0.6361 - val_accuracy: 0.6406\n",
      "Epoch 57/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6256 - accuracy: 0.6510 - val_loss: 0.6355 - val_accuracy: 0.6406\n",
      "Epoch 58/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6249 - accuracy: 0.6510 - val_loss: 0.6348 - val_accuracy: 0.6406\n",
      "Epoch 59/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6243 - accuracy: 0.6510 - val_loss: 0.6342 - val_accuracy: 0.6406\n",
      "Epoch 60/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.6236 - accuracy: 0.6528 - val_loss: 0.6335 - val_accuracy: 0.6406\n",
      "Epoch 61/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6230 - accuracy: 0.6528 - val_loss: 0.6329 - val_accuracy: 0.6406\n",
      "Epoch 62/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6223 - accuracy: 0.6528 - val_loss: 0.6322 - val_accuracy: 0.6406\n",
      "Epoch 63/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6217 - accuracy: 0.6528 - val_loss: 0.6316 - val_accuracy: 0.6406\n",
      "Epoch 64/200\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.6210 - accuracy: 0.6528 - val_loss: 0.6309 - val_accuracy: 0.6406\n",
      "Epoch 65/200\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6204 - accuracy: 0.6528 - val_loss: 0.6303 - val_accuracy: 0.6406\n",
      "Epoch 66/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6197 - accuracy: 0.6528 - val_loss: 0.6296 - val_accuracy: 0.6406\n",
      "Epoch 67/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6191 - accuracy: 0.6528 - val_loss: 0.6290 - val_accuracy: 0.6406\n",
      "Epoch 68/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6185 - accuracy: 0.6528 - val_loss: 0.6284 - val_accuracy: 0.6406\n",
      "Epoch 69/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.6179 - accuracy: 0.6528 - val_loss: 0.6277 - val_accuracy: 0.6406\n",
      "Epoch 70/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.6172 - accuracy: 0.6528 - val_loss: 0.6271 - val_accuracy: 0.6406\n",
      "Epoch 71/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.6166 - accuracy: 0.6528 - val_loss: 0.6265 - val_accuracy: 0.6406\n",
      "Epoch 72/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.6160 - accuracy: 0.6528 - val_loss: 0.6259 - val_accuracy: 0.6406\n",
      "Epoch 73/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.6153 - accuracy: 0.6528 - val_loss: 0.6252 - val_accuracy: 0.6406\n",
      "Epoch 74/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6147 - accuracy: 0.6528 - val_loss: 0.6246 - val_accuracy: 0.6406\n",
      "Epoch 75/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6141 - accuracy: 0.6528 - val_loss: 0.6240 - val_accuracy: 0.6406\n",
      "Epoch 76/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6135 - accuracy: 0.6528 - val_loss: 0.6234 - val_accuracy: 0.6406\n",
      "Epoch 77/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6129 - accuracy: 0.6528 - val_loss: 0.6228 - val_accuracy: 0.6406\n",
      "Epoch 78/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.6123 - accuracy: 0.6545 - val_loss: 0.6222 - val_accuracy: 0.6406\n",
      "Epoch 79/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.6117 - accuracy: 0.6545 - val_loss: 0.6216 - val_accuracy: 0.6406\n",
      "Epoch 80/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6111 - accuracy: 0.6545 - val_loss: 0.6210 - val_accuracy: 0.6406\n",
      "Epoch 81/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6105 - accuracy: 0.6545 - val_loss: 0.6204 - val_accuracy: 0.6406\n",
      "Epoch 82/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6099 - accuracy: 0.6545 - val_loss: 0.6198 - val_accuracy: 0.6406\n",
      "Epoch 83/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6093 - accuracy: 0.6545 - val_loss: 0.6192 - val_accuracy: 0.6406\n",
      "Epoch 84/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.6088 - accuracy: 0.6545 - val_loss: 0.6186 - val_accuracy: 0.6406\n",
      "Epoch 85/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6081 - accuracy: 0.6562 - val_loss: 0.6180 - val_accuracy: 0.6406\n",
      "Epoch 86/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6076 - accuracy: 0.6562 - val_loss: 0.6174 - val_accuracy: 0.6406\n",
      "Epoch 87/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6070 - accuracy: 0.6562 - val_loss: 0.6168 - val_accuracy: 0.6406\n",
      "Epoch 88/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6064 - accuracy: 0.6562 - val_loss: 0.6162 - val_accuracy: 0.6406\n",
      "Epoch 89/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6059 - accuracy: 0.6562 - val_loss: 0.6157 - val_accuracy: 0.6406\n",
      "Epoch 90/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6053 - accuracy: 0.6562 - val_loss: 0.6151 - val_accuracy: 0.6406\n",
      "Epoch 91/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.6047 - accuracy: 0.6580 - val_loss: 0.6145 - val_accuracy: 0.6406\n",
      "Epoch 92/200\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6041 - accuracy: 0.6562 - val_loss: 0.6139 - val_accuracy: 0.6406\n",
      "Epoch 93/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6036 - accuracy: 0.6580 - val_loss: 0.6134 - val_accuracy: 0.6406\n",
      "Epoch 94/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.6030 - accuracy: 0.6580 - val_loss: 0.6128 - val_accuracy: 0.6406\n",
      "Epoch 95/200\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.6025 - accuracy: 0.6562 - val_loss: 0.6122 - val_accuracy: 0.6406\n",
      "Epoch 96/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.6019 - accuracy: 0.6562 - val_loss: 0.6117 - val_accuracy: 0.6406\n",
      "Epoch 97/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.6013 - accuracy: 0.6562 - val_loss: 0.6111 - val_accuracy: 0.6406\n",
      "Epoch 98/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.6008 - accuracy: 0.6562 - val_loss: 0.6105 - val_accuracy: 0.6406\n",
      "Epoch 99/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.6002 - accuracy: 0.6597 - val_loss: 0.6100 - val_accuracy: 0.6406\n",
      "Epoch 100/200\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.5997 - accuracy: 0.6597 - val_loss: 0.6094 - val_accuracy: 0.6406\n",
      "Epoch 101/200\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5991 - accuracy: 0.6580 - val_loss: 0.6089 - val_accuracy: 0.6406\n",
      "Epoch 102/200\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5986 - accuracy: 0.6580 - val_loss: 0.6083 - val_accuracy: 0.6406\n",
      "Epoch 103/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5980 - accuracy: 0.6580 - val_loss: 0.6078 - val_accuracy: 0.6406\n",
      "Epoch 104/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5975 - accuracy: 0.6580 - val_loss: 0.6072 - val_accuracy: 0.6406\n",
      "Epoch 105/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5969 - accuracy: 0.6580 - val_loss: 0.6067 - val_accuracy: 0.6406\n",
      "Epoch 106/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5964 - accuracy: 0.6580 - val_loss: 0.6061 - val_accuracy: 0.6406\n",
      "Epoch 107/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5959 - accuracy: 0.6580 - val_loss: 0.6056 - val_accuracy: 0.6406\n",
      "Epoch 108/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5953 - accuracy: 0.6562 - val_loss: 0.6051 - val_accuracy: 0.6406\n",
      "Epoch 109/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5948 - accuracy: 0.6562 - val_loss: 0.6045 - val_accuracy: 0.6406\n",
      "Epoch 110/200\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5943 - accuracy: 0.6562 - val_loss: 0.6040 - val_accuracy: 0.6406\n",
      "Epoch 111/200\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5938 - accuracy: 0.6580 - val_loss: 0.6035 - val_accuracy: 0.6406\n",
      "Epoch 112/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5932 - accuracy: 0.6580 - val_loss: 0.6029 - val_accuracy: 0.6406\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 42us/step - loss: 0.5927 - accuracy: 0.6580 - val_loss: 0.6024 - val_accuracy: 0.6458\n",
      "Epoch 114/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5922 - accuracy: 0.6580 - val_loss: 0.6019 - val_accuracy: 0.6458\n",
      "Epoch 115/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5917 - accuracy: 0.6580 - val_loss: 0.6014 - val_accuracy: 0.6458\n",
      "Epoch 116/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5911 - accuracy: 0.6580 - val_loss: 0.6008 - val_accuracy: 0.6458\n",
      "Epoch 117/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5906 - accuracy: 0.6597 - val_loss: 0.6003 - val_accuracy: 0.6458\n",
      "Epoch 118/200\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5901 - accuracy: 0.6597 - val_loss: 0.5998 - val_accuracy: 0.6458\n",
      "Epoch 119/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5896 - accuracy: 0.6615 - val_loss: 0.5993 - val_accuracy: 0.6458\n",
      "Epoch 120/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5891 - accuracy: 0.6597 - val_loss: 0.5988 - val_accuracy: 0.6510\n",
      "Epoch 121/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5886 - accuracy: 0.6597 - val_loss: 0.5983 - val_accuracy: 0.6510\n",
      "Epoch 122/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5881 - accuracy: 0.6597 - val_loss: 0.5978 - val_accuracy: 0.6510\n",
      "Epoch 123/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5876 - accuracy: 0.6580 - val_loss: 0.5973 - val_accuracy: 0.6562\n",
      "Epoch 124/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5871 - accuracy: 0.6580 - val_loss: 0.5968 - val_accuracy: 0.6562\n",
      "Epoch 125/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5866 - accuracy: 0.6580 - val_loss: 0.5963 - val_accuracy: 0.6562\n",
      "Epoch 126/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5861 - accuracy: 0.6580 - val_loss: 0.5958 - val_accuracy: 0.6562\n",
      "Epoch 127/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5856 - accuracy: 0.6580 - val_loss: 0.5953 - val_accuracy: 0.6562\n",
      "Epoch 128/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5851 - accuracy: 0.6580 - val_loss: 0.5948 - val_accuracy: 0.6615\n",
      "Epoch 129/200\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.5846 - accuracy: 0.6580 - val_loss: 0.5943 - val_accuracy: 0.6615\n",
      "Epoch 130/200\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.5841 - accuracy: 0.6580 - val_loss: 0.5938 - val_accuracy: 0.6615\n",
      "Epoch 131/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5836 - accuracy: 0.6580 - val_loss: 0.5933 - val_accuracy: 0.6667\n",
      "Epoch 132/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5832 - accuracy: 0.6580 - val_loss: 0.5928 - val_accuracy: 0.6667\n",
      "Epoch 133/200\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.5827 - accuracy: 0.6580 - val_loss: 0.5923 - val_accuracy: 0.6719\n",
      "Epoch 134/200\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.5822 - accuracy: 0.6580 - val_loss: 0.5918 - val_accuracy: 0.6719\n",
      "Epoch 135/200\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.5817 - accuracy: 0.6580 - val_loss: 0.5914 - val_accuracy: 0.6719\n",
      "Epoch 136/200\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5813 - accuracy: 0.6580 - val_loss: 0.5909 - val_accuracy: 0.6719\n",
      "Epoch 137/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5808 - accuracy: 0.6580 - val_loss: 0.5904 - val_accuracy: 0.6719\n",
      "Epoch 138/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5803 - accuracy: 0.6580 - val_loss: 0.5899 - val_accuracy: 0.6719\n",
      "Epoch 139/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5798 - accuracy: 0.6597 - val_loss: 0.5895 - val_accuracy: 0.6771\n",
      "Epoch 140/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5793 - accuracy: 0.6597 - val_loss: 0.5890 - val_accuracy: 0.6771\n",
      "Epoch 141/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5789 - accuracy: 0.6615 - val_loss: 0.5885 - val_accuracy: 0.6771\n",
      "Epoch 142/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5784 - accuracy: 0.6597 - val_loss: 0.5880 - val_accuracy: 0.6771\n",
      "Epoch 143/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5780 - accuracy: 0.6597 - val_loss: 0.5876 - val_accuracy: 0.6771\n",
      "Epoch 144/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5775 - accuracy: 0.6580 - val_loss: 0.5871 - val_accuracy: 0.6823\n",
      "Epoch 145/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5771 - accuracy: 0.6580 - val_loss: 0.5867 - val_accuracy: 0.6875\n",
      "Epoch 146/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5766 - accuracy: 0.6615 - val_loss: 0.5862 - val_accuracy: 0.6927\n",
      "Epoch 147/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5761 - accuracy: 0.6615 - val_loss: 0.5857 - val_accuracy: 0.6927\n",
      "Epoch 148/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5757 - accuracy: 0.6615 - val_loss: 0.5853 - val_accuracy: 0.6979\n",
      "Epoch 149/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5752 - accuracy: 0.6649 - val_loss: 0.5848 - val_accuracy: 0.7031\n",
      "Epoch 150/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5747 - accuracy: 0.6649 - val_loss: 0.5844 - val_accuracy: 0.7031\n",
      "Epoch 151/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5743 - accuracy: 0.6667 - val_loss: 0.5839 - val_accuracy: 0.7031\n",
      "Epoch 152/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5739 - accuracy: 0.6667 - val_loss: 0.5835 - val_accuracy: 0.7031\n",
      "Epoch 153/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5734 - accuracy: 0.6667 - val_loss: 0.5830 - val_accuracy: 0.7031\n",
      "Epoch 154/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5730 - accuracy: 0.6667 - val_loss: 0.5826 - val_accuracy: 0.7083\n",
      "Epoch 155/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5725 - accuracy: 0.6684 - val_loss: 0.5821 - val_accuracy: 0.7135\n",
      "Epoch 156/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5721 - accuracy: 0.6684 - val_loss: 0.5817 - val_accuracy: 0.7135\n",
      "Epoch 157/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5716 - accuracy: 0.6701 - val_loss: 0.5813 - val_accuracy: 0.7135\n",
      "Epoch 158/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5712 - accuracy: 0.6719 - val_loss: 0.5808 - val_accuracy: 0.7135\n",
      "Epoch 159/200\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5708 - accuracy: 0.6736 - val_loss: 0.5804 - val_accuracy: 0.7135\n",
      "Epoch 160/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5703 - accuracy: 0.6736 - val_loss: 0.5800 - val_accuracy: 0.7135\n",
      "Epoch 161/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5699 - accuracy: 0.6736 - val_loss: 0.5795 - val_accuracy: 0.7135\n",
      "Epoch 162/200\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5695 - accuracy: 0.6753 - val_loss: 0.5791 - val_accuracy: 0.7135\n",
      "Epoch 163/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5690 - accuracy: 0.6753 - val_loss: 0.5787 - val_accuracy: 0.7135\n",
      "Epoch 164/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5686 - accuracy: 0.6753 - val_loss: 0.5782 - val_accuracy: 0.7135\n",
      "Epoch 165/200\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.5682 - accuracy: 0.6771 - val_loss: 0.5778 - val_accuracy: 0.7135\n",
      "Epoch 166/200\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5677 - accuracy: 0.6771 - val_loss: 0.5774 - val_accuracy: 0.7135\n",
      "Epoch 167/200\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5673 - accuracy: 0.6771 - val_loss: 0.5770 - val_accuracy: 0.7135\n",
      "Epoch 168/200\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5669 - accuracy: 0.6771 - val_loss: 0.5766 - val_accuracy: 0.7135\n",
      "Epoch 169/200\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.5665 - accuracy: 0.6771 - val_loss: 0.5761 - val_accuracy: 0.7135\n",
      "Epoch 170/200\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5661 - accuracy: 0.6771 - val_loss: 0.5757 - val_accuracy: 0.7135\n",
      "Epoch 171/200\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5657 - accuracy: 0.6823 - val_loss: 0.5753 - val_accuracy: 0.7188\n",
      "Epoch 172/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5653 - accuracy: 0.6823 - val_loss: 0.5749 - val_accuracy: 0.7188\n",
      "Epoch 173/200\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5648 - accuracy: 0.6823 - val_loss: 0.5745 - val_accuracy: 0.7188\n",
      "Epoch 174/200\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.5644 - accuracy: 0.6823 - val_loss: 0.5741 - val_accuracy: 0.7188\n",
      "Epoch 175/200\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.5640 - accuracy: 0.6823 - val_loss: 0.5737 - val_accuracy: 0.7188\n",
      "Epoch 176/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5636 - accuracy: 0.6823 - val_loss: 0.5733 - val_accuracy: 0.7188\n",
      "Epoch 177/200\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.5632 - accuracy: 0.6823 - val_loss: 0.5729 - val_accuracy: 0.7188\n",
      "Epoch 178/200\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.5628 - accuracy: 0.6823 - val_loss: 0.5725 - val_accuracy: 0.7188\n",
      "Epoch 179/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5624 - accuracy: 0.6823 - val_loss: 0.5720 - val_accuracy: 0.7188\n",
      "Epoch 180/200\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.5620 - accuracy: 0.6806 - val_loss: 0.5717 - val_accuracy: 0.7188\n",
      "Epoch 181/200\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.5616 - accuracy: 0.6806 - val_loss: 0.5713 - val_accuracy: 0.7188\n",
      "Epoch 182/200\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5612 - accuracy: 0.6806 - val_loss: 0.5709 - val_accuracy: 0.7188\n",
      "Epoch 183/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5608 - accuracy: 0.6788 - val_loss: 0.5705 - val_accuracy: 0.7188\n",
      "Epoch 184/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5604 - accuracy: 0.6806 - val_loss: 0.5701 - val_accuracy: 0.7188\n",
      "Epoch 185/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5600 - accuracy: 0.6840 - val_loss: 0.5697 - val_accuracy: 0.7188\n",
      "Epoch 186/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5596 - accuracy: 0.6858 - val_loss: 0.5693 - val_accuracy: 0.7188\n",
      "Epoch 187/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5592 - accuracy: 0.6858 - val_loss: 0.5689 - val_accuracy: 0.7188\n",
      "Epoch 188/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5588 - accuracy: 0.6892 - val_loss: 0.5685 - val_accuracy: 0.7188\n",
      "Epoch 189/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5584 - accuracy: 0.6910 - val_loss: 0.5681 - val_accuracy: 0.7188\n",
      "Epoch 190/200\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5580 - accuracy: 0.6944 - val_loss: 0.5677 - val_accuracy: 0.7188\n",
      "Epoch 191/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5576 - accuracy: 0.6944 - val_loss: 0.5674 - val_accuracy: 0.7188\n",
      "Epoch 192/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5572 - accuracy: 0.6944 - val_loss: 0.5670 - val_accuracy: 0.7188\n",
      "Epoch 193/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5569 - accuracy: 0.6944 - val_loss: 0.5666 - val_accuracy: 0.7240\n",
      "Epoch 194/200\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5565 - accuracy: 0.6944 - val_loss: 0.5662 - val_accuracy: 0.7188\n",
      "Epoch 195/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5561 - accuracy: 0.6997 - val_loss: 0.5659 - val_accuracy: 0.7188\n",
      "Epoch 196/200\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5557 - accuracy: 0.6997 - val_loss: 0.5655 - val_accuracy: 0.7188\n",
      "Epoch 197/200\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5554 - accuracy: 0.7014 - val_loss: 0.5651 - val_accuracy: 0.7188\n",
      "Epoch 198/200\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5550 - accuracy: 0.7014 - val_loss: 0.5647 - val_accuracy: 0.7188\n",
      "Epoch 199/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5546 - accuracy: 0.7014 - val_loss: 0.5644 - val_accuracy: 0.7188\n",
      "Epoch 200/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5542 - accuracy: 0.7049 - val_loss: 0.5640 - val_accuracy: 0.7188\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Like we did for the Random Forest, Generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37394506],\n",
       "       [0.46128416],\n",
       "       [0.3499563 ],\n",
       "       [0.43481714],\n",
       "       [0.2766018 ],\n",
       "       [0.3462882 ],\n",
       "       [0.21218947],\n",
       "       [0.39196223],\n",
       "       [0.54910594],\n",
       "       [0.30893642]], dtype=float32)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.719\n",
      "roc-auc is 0.797\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29e1dade898>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5539 - accuracy: 0.7049 - val_loss: 0.5636 - val_accuracy: 0.7188\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5535 - accuracy: 0.7049 - val_loss: 0.5633 - val_accuracy: 0.7188\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5531 - accuracy: 0.7049 - val_loss: 0.5629 - val_accuracy: 0.7188\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5527 - accuracy: 0.7049 - val_loss: 0.5626 - val_accuracy: 0.7188\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5524 - accuracy: 0.7031 - val_loss: 0.5622 - val_accuracy: 0.7188\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5520 - accuracy: 0.7049 - val_loss: 0.5618 - val_accuracy: 0.7188\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.5516 - accuracy: 0.7083 - val_loss: 0.5615 - val_accuracy: 0.7188\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.5513 - accuracy: 0.7083 - val_loss: 0.5611 - val_accuracy: 0.7188\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.5509 - accuracy: 0.7101 - val_loss: 0.5608 - val_accuracy: 0.7188\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5506 - accuracy: 0.7118 - val_loss: 0.5604 - val_accuracy: 0.7188\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5502 - accuracy: 0.7118 - val_loss: 0.5601 - val_accuracy: 0.7188\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.5498 - accuracy: 0.7135 - val_loss: 0.5597 - val_accuracy: 0.7188\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5495 - accuracy: 0.7135 - val_loss: 0.5594 - val_accuracy: 0.7188\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5491 - accuracy: 0.7153 - val_loss: 0.5590 - val_accuracy: 0.7188\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5488 - accuracy: 0.7153 - val_loss: 0.5587 - val_accuracy: 0.7188\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5484 - accuracy: 0.7153 - val_loss: 0.5583 - val_accuracy: 0.7188\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5481 - accuracy: 0.7135 - val_loss: 0.5580 - val_accuracy: 0.7188\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5477 - accuracy: 0.7153 - val_loss: 0.5577 - val_accuracy: 0.7188\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5474 - accuracy: 0.7153 - val_loss: 0.5573 - val_accuracy: 0.7188\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5470 - accuracy: 0.7188 - val_loss: 0.5570 - val_accuracy: 0.7188\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.5467 - accuracy: 0.7170 - val_loss: 0.5566 - val_accuracy: 0.7188\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5464 - accuracy: 0.7188 - val_loss: 0.5563 - val_accuracy: 0.7188\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.5460 - accuracy: 0.7188 - val_loss: 0.5560 - val_accuracy: 0.7188\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.5457 - accuracy: 0.7188 - val_loss: 0.5556 - val_accuracy: 0.7188\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.5453 - accuracy: 0.7205 - val_loss: 0.5553 - val_accuracy: 0.7188\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.5450 - accuracy: 0.7205 - val_loss: 0.5550 - val_accuracy: 0.7240\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.5447 - accuracy: 0.7205 - val_loss: 0.5547 - val_accuracy: 0.7240\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5443 - accuracy: 0.7222 - val_loss: 0.5543 - val_accuracy: 0.7292\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5440 - accuracy: 0.7222 - val_loss: 0.5540 - val_accuracy: 0.7292\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5437 - accuracy: 0.7222 - val_loss: 0.5537 - val_accuracy: 0.7292\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5433 - accuracy: 0.7240 - val_loss: 0.5534 - val_accuracy: 0.7292\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5430 - accuracy: 0.7257 - val_loss: 0.5530 - val_accuracy: 0.7292\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.5427 - accuracy: 0.7257 - val_loss: 0.5527 - val_accuracy: 0.7292\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5424 - accuracy: 0.7274 - val_loss: 0.5524 - val_accuracy: 0.7292\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5420 - accuracy: 0.7274 - val_loss: 0.5521 - val_accuracy: 0.7344\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5417 - accuracy: 0.7274 - val_loss: 0.5518 - val_accuracy: 0.7344\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.5414 - accuracy: 0.7274 - val_loss: 0.5515 - val_accuracy: 0.7292\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.5411 - accuracy: 0.7274 - val_loss: 0.5511 - val_accuracy: 0.7292\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.5407 - accuracy: 0.7274 - val_loss: 0.5508 - val_accuracy: 0.7292\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5404 - accuracy: 0.7274 - val_loss: 0.5505 - val_accuracy: 0.7292\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5401 - accuracy: 0.7274 - val_loss: 0.5502 - val_accuracy: 0.7292\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5398 - accuracy: 0.7309 - val_loss: 0.5499 - val_accuracy: 0.7344\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5394 - accuracy: 0.7309 - val_loss: 0.5496 - val_accuracy: 0.7344\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5391 - accuracy: 0.7292 - val_loss: 0.5493 - val_accuracy: 0.7344\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5388 - accuracy: 0.7292 - val_loss: 0.5490 - val_accuracy: 0.7344\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5385 - accuracy: 0.7292 - val_loss: 0.5487 - val_accuracy: 0.7344\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5382 - accuracy: 0.7292 - val_loss: 0.5484 - val_accuracy: 0.7344\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.5379 - accuracy: 0.7309 - val_loss: 0.5481 - val_accuracy: 0.7344\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.5376 - accuracy: 0.7309 - val_loss: 0.5478 - val_accuracy: 0.7344\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.5373 - accuracy: 0.7326 - val_loss: 0.5475 - val_accuracy: 0.7344\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.5370 - accuracy: 0.7326 - val_loss: 0.5472 - val_accuracy: 0.7292\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.5366 - accuracy: 0.7326 - val_loss: 0.5469 - val_accuracy: 0.7292\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5363 - accuracy: 0.7326 - val_loss: 0.5466 - val_accuracy: 0.7292\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.5361 - accuracy: 0.7326 - val_loss: 0.5463 - val_accuracy: 0.7292\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.5357 - accuracy: 0.7309 - val_loss: 0.5460 - val_accuracy: 0.7292\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5354 - accuracy: 0.7309 - val_loss: 0.5458 - val_accuracy: 0.7292\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.5351 - accuracy: 0.7309 - val_loss: 0.5455 - val_accuracy: 0.7344\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5349 - accuracy: 0.7309 - val_loss: 0.5452 - val_accuracy: 0.7344\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5345 - accuracy: 0.7309 - val_loss: 0.5449 - val_accuracy: 0.7344\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.5343 - accuracy: 0.7326 - val_loss: 0.5446 - val_accuracy: 0.7344\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.5340 - accuracy: 0.7344 - val_loss: 0.5443 - val_accuracy: 0.7344\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5337 - accuracy: 0.7344 - val_loss: 0.5441 - val_accuracy: 0.7396\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5334 - accuracy: 0.7344 - val_loss: 0.5438 - val_accuracy: 0.7396\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5331 - accuracy: 0.7344 - val_loss: 0.5435 - val_accuracy: 0.7396\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5328 - accuracy: 0.7344 - val_loss: 0.5432 - val_accuracy: 0.7344\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5325 - accuracy: 0.7344 - val_loss: 0.5429 - val_accuracy: 0.7344\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5322 - accuracy: 0.7344 - val_loss: 0.5427 - val_accuracy: 0.7344\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5319 - accuracy: 0.7344 - val_loss: 0.5424 - val_accuracy: 0.7344\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5316 - accuracy: 0.7361 - val_loss: 0.5421 - val_accuracy: 0.7344\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5314 - accuracy: 0.7344 - val_loss: 0.5419 - val_accuracy: 0.7344\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5311 - accuracy: 0.7344 - val_loss: 0.5416 - val_accuracy: 0.7344\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5308 - accuracy: 0.7361 - val_loss: 0.5413 - val_accuracy: 0.7344\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5305 - accuracy: 0.7378 - val_loss: 0.5410 - val_accuracy: 0.7344\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5302 - accuracy: 0.7396 - val_loss: 0.5408 - val_accuracy: 0.7344\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5300 - accuracy: 0.7396 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5297 - accuracy: 0.7431 - val_loss: 0.5403 - val_accuracy: 0.7292\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5294 - accuracy: 0.7431 - val_loss: 0.5400 - val_accuracy: 0.7292\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5291 - accuracy: 0.7413 - val_loss: 0.5397 - val_accuracy: 0.7344\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5288 - accuracy: 0.7431 - val_loss: 0.5395 - val_accuracy: 0.7344\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5286 - accuracy: 0.7431 - val_loss: 0.5392 - val_accuracy: 0.7344\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5283 - accuracy: 0.7431 - val_loss: 0.5390 - val_accuracy: 0.7396\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5280 - accuracy: 0.7448 - val_loss: 0.5387 - val_accuracy: 0.7396\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5278 - accuracy: 0.7431 - val_loss: 0.5384 - val_accuracy: 0.7396\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5275 - accuracy: 0.7431 - val_loss: 0.5382 - val_accuracy: 0.7344\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.5272 - accuracy: 0.7448 - val_loss: 0.5379 - val_accuracy: 0.7344\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.5270 - accuracy: 0.7448 - val_loss: 0.5377 - val_accuracy: 0.7344\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5267 - accuracy: 0.7448 - val_loss: 0.5374 - val_accuracy: 0.7344\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5265 - accuracy: 0.7448 - val_loss: 0.5372 - val_accuracy: 0.7344\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5262 - accuracy: 0.7448 - val_loss: 0.5369 - val_accuracy: 0.7344\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5259 - accuracy: 0.7448 - val_loss: 0.5367 - val_accuracy: 0.7292\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.5256 - accuracy: 0.7448 - val_loss: 0.5364 - val_accuracy: 0.7292\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.5254 - accuracy: 0.7448 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.5251 - accuracy: 0.7448 - val_loss: 0.5360 - val_accuracy: 0.7292\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.5249 - accuracy: 0.7448 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5246 - accuracy: 0.7448 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.5243 - accuracy: 0.7448 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5241 - accuracy: 0.7448 - val_loss: 0.5350 - val_accuracy: 0.7344\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5238 - accuracy: 0.7431 - val_loss: 0.5347 - val_accuracy: 0.7344\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5236 - accuracy: 0.7431 - val_loss: 0.5345 - val_accuracy: 0.7396\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5233 - accuracy: 0.7448 - val_loss: 0.5343 - val_accuracy: 0.7396\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29e1d9cbbe0>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?\n",
    "\n",
    "**ANSWER**: From the above example, it begins to stabilize (with minor fluctuations) at Epoch #605"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "Do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(777, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>6</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.8</td>\n",
       "      <td>0.177</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.2</td>\n",
       "      <td>0.270</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>4</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.610</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>10</td>\n",
       "      <td>122.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>0.258</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>5</td>\n",
       "      <td>144.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.452</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "714              6                    80.0            80.0            36.0   \n",
       "87               0                   131.0             0.0             0.0   \n",
       "652              4                    90.0             0.0             0.0   \n",
       "255             10                   122.0            68.0             0.0   \n",
       "397              5                   144.0            82.0            26.0   \n",
       "\n",
       "     insulin   bmi  pedigree_function   age  has_diabetes  \n",
       "714      0.0  39.8              0.177  28.0           0.0  \n",
       "87       0.0  43.2              0.270  26.0           1.0  \n",
       "652      0.0  28.0              0.610  31.0           0.0  \n",
       "255      0.0  31.2              0.258  41.0           0.0  \n",
       "397    285.0  32.0              0.452  58.0           1.0  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write your code here. \n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "#read in data using pandas\n",
    "file = \"pima-indians-diabetes.csv\"\n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "train_df = pd.read_csv(file, names=names)\n",
    "\n",
    "#Output data to check\n",
    "print(train_df.shape)\n",
    "train_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_df.iloc[:, :-1].values\n",
    "y = train_df[\"has_diabetes\"].values\n",
    "\n",
    "X = X[9:]\n",
    "y = y[9:]\n",
    "\n",
    "# Split the data to Train, and Test (75%, 25%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)\n",
    "\n",
    "np.mean(y), np.mean(1-y)\n",
    "\n",
    "#Split Dataset\n",
    "#X_train\n",
    "#y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "#create model\n",
    "model = Sequential()\n",
    "\n",
    "#Get number of columns in training data\n",
    "    #ITC, 8\n",
    "n_cols = X_train[1]\n",
    "\n",
    "#(!!!) DEVIATION FROM TUTORIAL, USED ORIGINAL BOILERPLATE\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 103\n",
      "Trainable params: 103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Two-hidden layer NN\n",
    "    #input shape is 8 because of 8 inputs\n",
    "    #Changing activation to relu for both of our hidden layers\n",
    "    #Each hidden layer has 6 nodes each\n",
    "    #Sigmoid final layer\n",
    "    \n",
    "model_2 = Sequential([\n",
    "    Dense(6, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(6, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/1500\n",
      "576/576 [==============================] - 0s 182us/step - loss: 0.7476 - accuracy: 0.4028 - val_loss: 0.7331 - val_accuracy: 0.4375\n",
      "Epoch 2/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.7392 - accuracy: 0.4062 - val_loss: 0.7260 - val_accuracy: 0.4583\n",
      "Epoch 3/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.7315 - accuracy: 0.4219 - val_loss: 0.7195 - val_accuracy: 0.4896\n",
      "Epoch 4/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.7244 - accuracy: 0.4323 - val_loss: 0.7135 - val_accuracy: 0.4896\n",
      "Epoch 5/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.7178 - accuracy: 0.4444 - val_loss: 0.7079 - val_accuracy: 0.5000\n",
      "Epoch 6/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.7118 - accuracy: 0.4549 - val_loss: 0.7027 - val_accuracy: 0.5469\n",
      "Epoch 7/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.7061 - accuracy: 0.4757 - val_loss: 0.6979 - val_accuracy: 0.5469\n",
      "Epoch 8/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.7008 - accuracy: 0.5087 - val_loss: 0.6935 - val_accuracy: 0.5625\n",
      "Epoch 9/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6959 - accuracy: 0.5469 - val_loss: 0.6893 - val_accuracy: 0.5729\n",
      "Epoch 10/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6912 - accuracy: 0.5729 - val_loss: 0.6855 - val_accuracy: 0.5781\n",
      "Epoch 11/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6869 - accuracy: 0.5990 - val_loss: 0.6819 - val_accuracy: 0.6042\n",
      "Epoch 12/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6828 - accuracy: 0.6042 - val_loss: 0.6785 - val_accuracy: 0.6146\n",
      "Epoch 13/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6789 - accuracy: 0.6181 - val_loss: 0.6752 - val_accuracy: 0.6354\n",
      "Epoch 14/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6752 - accuracy: 0.6233 - val_loss: 0.6722 - val_accuracy: 0.6302\n",
      "Epoch 15/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.6717 - accuracy: 0.6267 - val_loss: 0.6693 - val_accuracy: 0.6406\n",
      "Epoch 16/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.6684 - accuracy: 0.6337 - val_loss: 0.6665 - val_accuracy: 0.6354\n",
      "Epoch 17/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.6652 - accuracy: 0.6372 - val_loss: 0.6639 - val_accuracy: 0.6354\n",
      "Epoch 18/1500\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.6622 - accuracy: 0.6493 - val_loss: 0.6614 - val_accuracy: 0.6458\n",
      "Epoch 19/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6593 - accuracy: 0.6510 - val_loss: 0.6590 - val_accuracy: 0.6458\n",
      "Epoch 20/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.6565 - accuracy: 0.6545 - val_loss: 0.6567 - val_accuracy: 0.6510\n",
      "Epoch 21/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6538 - accuracy: 0.6528 - val_loss: 0.6545 - val_accuracy: 0.6615\n",
      "Epoch 22/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6513 - accuracy: 0.6510 - val_loss: 0.6524 - val_accuracy: 0.6615\n",
      "Epoch 23/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6488 - accuracy: 0.6510 - val_loss: 0.6503 - val_accuracy: 0.6667\n",
      "Epoch 24/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.6465 - accuracy: 0.6493 - val_loss: 0.6483 - val_accuracy: 0.6667\n",
      "Epoch 25/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.6442 - accuracy: 0.6510 - val_loss: 0.6463 - val_accuracy: 0.6667\n",
      "Epoch 26/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6419 - accuracy: 0.6615 - val_loss: 0.6444 - val_accuracy: 0.6615\n",
      "Epoch 27/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.6398 - accuracy: 0.6649 - val_loss: 0.6425 - val_accuracy: 0.6667\n",
      "Epoch 28/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.6377 - accuracy: 0.6632 - val_loss: 0.6407 - val_accuracy: 0.6667\n",
      "Epoch 29/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6357 - accuracy: 0.6701 - val_loss: 0.6390 - val_accuracy: 0.6719\n",
      "Epoch 30/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6337 - accuracy: 0.6684 - val_loss: 0.6373 - val_accuracy: 0.6719\n",
      "Epoch 31/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6318 - accuracy: 0.6701 - val_loss: 0.6356 - val_accuracy: 0.6719\n",
      "Epoch 32/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6300 - accuracy: 0.6719 - val_loss: 0.6340 - val_accuracy: 0.6719\n",
      "Epoch 33/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6283 - accuracy: 0.6719 - val_loss: 0.6325 - val_accuracy: 0.6719\n",
      "Epoch 34/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6266 - accuracy: 0.6736 - val_loss: 0.6310 - val_accuracy: 0.6771\n",
      "Epoch 35/1500\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.6249 - accuracy: 0.6736 - val_loss: 0.6295 - val_accuracy: 0.6823\n",
      "Epoch 36/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.6233 - accuracy: 0.6753 - val_loss: 0.6281 - val_accuracy: 0.6823\n",
      "Epoch 37/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6217 - accuracy: 0.6806 - val_loss: 0.6267 - val_accuracy: 0.6823\n",
      "Epoch 38/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6202 - accuracy: 0.6840 - val_loss: 0.6253 - val_accuracy: 0.6875\n",
      "Epoch 39/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6188 - accuracy: 0.6823 - val_loss: 0.6240 - val_accuracy: 0.6979\n",
      "Epoch 40/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6173 - accuracy: 0.6858 - val_loss: 0.6226 - val_accuracy: 0.6927\n",
      "Epoch 41/1500\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.6159 - accuracy: 0.6892 - val_loss: 0.6214 - val_accuracy: 0.6875\n",
      "Epoch 42/1500\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.6145 - accuracy: 0.6910 - val_loss: 0.6201 - val_accuracy: 0.6927\n",
      "Epoch 43/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.6132 - accuracy: 0.6910 - val_loss: 0.6188 - val_accuracy: 0.6875\n",
      "Epoch 44/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.6119 - accuracy: 0.6944 - val_loss: 0.6176 - val_accuracy: 0.6875\n",
      "Epoch 45/1500\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.6106 - accuracy: 0.6962 - val_loss: 0.6164 - val_accuracy: 0.6875\n",
      "Epoch 46/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6093 - accuracy: 0.6962 - val_loss: 0.6152 - val_accuracy: 0.6927\n",
      "Epoch 47/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.6080 - accuracy: 0.6944 - val_loss: 0.6140 - val_accuracy: 0.6927\n",
      "Epoch 48/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6068 - accuracy: 0.6962 - val_loss: 0.6129 - val_accuracy: 0.6927\n",
      "Epoch 49/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6055 - accuracy: 0.6979 - val_loss: 0.6117 - val_accuracy: 0.6979\n",
      "Epoch 50/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.6043 - accuracy: 0.6979 - val_loss: 0.6107 - val_accuracy: 0.6979\n",
      "Epoch 51/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.6031 - accuracy: 0.6997 - val_loss: 0.6096 - val_accuracy: 0.6979\n",
      "Epoch 52/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6020 - accuracy: 0.7031 - val_loss: 0.6085 - val_accuracy: 0.6927\n",
      "Epoch 53/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.6008 - accuracy: 0.7049 - val_loss: 0.6075 - val_accuracy: 0.6927\n",
      "Epoch 54/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5997 - accuracy: 0.7049 - val_loss: 0.6064 - val_accuracy: 0.6927\n",
      "Epoch 55/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5986 - accuracy: 0.7083 - val_loss: 0.6054 - val_accuracy: 0.6927\n",
      "Epoch 56/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.5975 - accuracy: 0.7118 - val_loss: 0.6044 - val_accuracy: 0.6927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1500\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.5964 - accuracy: 0.7118 - val_loss: 0.6034 - val_accuracy: 0.6875\n",
      "Epoch 58/1500\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.5953 - accuracy: 0.7135 - val_loss: 0.6024 - val_accuracy: 0.6875\n",
      "Epoch 59/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5943 - accuracy: 0.7118 - val_loss: 0.6014 - val_accuracy: 0.6875\n",
      "Epoch 60/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5932 - accuracy: 0.7118 - val_loss: 0.6005 - val_accuracy: 0.6927\n",
      "Epoch 61/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.5922 - accuracy: 0.7135 - val_loss: 0.5996 - val_accuracy: 0.6927\n",
      "Epoch 62/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5912 - accuracy: 0.7118 - val_loss: 0.5986 - val_accuracy: 0.6927\n",
      "Epoch 63/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5902 - accuracy: 0.7153 - val_loss: 0.5977 - val_accuracy: 0.6927\n",
      "Epoch 64/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5892 - accuracy: 0.7153 - val_loss: 0.5968 - val_accuracy: 0.6979\n",
      "Epoch 65/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5882 - accuracy: 0.7118 - val_loss: 0.5959 - val_accuracy: 0.6979\n",
      "Epoch 66/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5872 - accuracy: 0.7118 - val_loss: 0.5951 - val_accuracy: 0.6979\n",
      "Epoch 67/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5862 - accuracy: 0.7135 - val_loss: 0.5942 - val_accuracy: 0.6979\n",
      "Epoch 68/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5853 - accuracy: 0.7153 - val_loss: 0.5934 - val_accuracy: 0.6979\n",
      "Epoch 69/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5843 - accuracy: 0.7188 - val_loss: 0.5925 - val_accuracy: 0.6927\n",
      "Epoch 70/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5834 - accuracy: 0.7240 - val_loss: 0.5917 - val_accuracy: 0.6927\n",
      "Epoch 71/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5825 - accuracy: 0.7257 - val_loss: 0.5909 - val_accuracy: 0.6927\n",
      "Epoch 72/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5816 - accuracy: 0.7257 - val_loss: 0.5901 - val_accuracy: 0.6979\n",
      "Epoch 73/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5807 - accuracy: 0.7222 - val_loss: 0.5893 - val_accuracy: 0.6979\n",
      "Epoch 74/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5798 - accuracy: 0.7222 - val_loss: 0.5885 - val_accuracy: 0.6979\n",
      "Epoch 75/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5789 - accuracy: 0.7205 - val_loss: 0.5878 - val_accuracy: 0.6979\n",
      "Epoch 76/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5780 - accuracy: 0.7205 - val_loss: 0.5870 - val_accuracy: 0.6979\n",
      "Epoch 77/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5772 - accuracy: 0.7205 - val_loss: 0.5863 - val_accuracy: 0.6979\n",
      "Epoch 78/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5764 - accuracy: 0.7240 - val_loss: 0.5855 - val_accuracy: 0.6979\n",
      "Epoch 79/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5755 - accuracy: 0.7240 - val_loss: 0.5848 - val_accuracy: 0.6979\n",
      "Epoch 80/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5747 - accuracy: 0.7240 - val_loss: 0.5841 - val_accuracy: 0.6979\n",
      "Epoch 81/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5738 - accuracy: 0.7240 - val_loss: 0.5834 - val_accuracy: 0.6979\n",
      "Epoch 82/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5730 - accuracy: 0.7240 - val_loss: 0.5827 - val_accuracy: 0.7031\n",
      "Epoch 83/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5722 - accuracy: 0.7240 - val_loss: 0.5820 - val_accuracy: 0.7083\n",
      "Epoch 84/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5714 - accuracy: 0.7257 - val_loss: 0.5813 - val_accuracy: 0.7083\n",
      "Epoch 85/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5706 - accuracy: 0.7240 - val_loss: 0.5807 - val_accuracy: 0.7083\n",
      "Epoch 86/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5698 - accuracy: 0.7274 - val_loss: 0.5800 - val_accuracy: 0.7083\n",
      "Epoch 87/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5690 - accuracy: 0.7274 - val_loss: 0.5793 - val_accuracy: 0.7083\n",
      "Epoch 88/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.5682 - accuracy: 0.7292 - val_loss: 0.5787 - val_accuracy: 0.7031\n",
      "Epoch 89/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5675 - accuracy: 0.7274 - val_loss: 0.5780 - val_accuracy: 0.7083\n",
      "Epoch 90/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5667 - accuracy: 0.7292 - val_loss: 0.5774 - val_accuracy: 0.7031\n",
      "Epoch 91/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5660 - accuracy: 0.7292 - val_loss: 0.5767 - val_accuracy: 0.7031\n",
      "Epoch 92/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5652 - accuracy: 0.7309 - val_loss: 0.5761 - val_accuracy: 0.7031\n",
      "Epoch 93/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5645 - accuracy: 0.7309 - val_loss: 0.5755 - val_accuracy: 0.7031\n",
      "Epoch 94/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5638 - accuracy: 0.7326 - val_loss: 0.5749 - val_accuracy: 0.7031\n",
      "Epoch 95/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5630 - accuracy: 0.7326 - val_loss: 0.5743 - val_accuracy: 0.7031\n",
      "Epoch 96/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5624 - accuracy: 0.7344 - val_loss: 0.5737 - val_accuracy: 0.7031\n",
      "Epoch 97/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5616 - accuracy: 0.7344 - val_loss: 0.5732 - val_accuracy: 0.7031\n",
      "Epoch 98/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5610 - accuracy: 0.7344 - val_loss: 0.5726 - val_accuracy: 0.7031\n",
      "Epoch 99/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5603 - accuracy: 0.7309 - val_loss: 0.5720 - val_accuracy: 0.7031\n",
      "Epoch 100/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5596 - accuracy: 0.7309 - val_loss: 0.5715 - val_accuracy: 0.7083\n",
      "Epoch 101/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5589 - accuracy: 0.7309 - val_loss: 0.5709 - val_accuracy: 0.7083\n",
      "Epoch 102/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5583 - accuracy: 0.7292 - val_loss: 0.5704 - val_accuracy: 0.7083\n",
      "Epoch 103/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5576 - accuracy: 0.7292 - val_loss: 0.5699 - val_accuracy: 0.7083\n",
      "Epoch 104/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.5569 - accuracy: 0.7292 - val_loss: 0.5693 - val_accuracy: 0.7083\n",
      "Epoch 105/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5563 - accuracy: 0.7309 - val_loss: 0.5688 - val_accuracy: 0.7083\n",
      "Epoch 106/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5556 - accuracy: 0.7292 - val_loss: 0.5683 - val_accuracy: 0.7083\n",
      "Epoch 107/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5549 - accuracy: 0.7309 - val_loss: 0.5678 - val_accuracy: 0.7083\n",
      "Epoch 108/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5543 - accuracy: 0.7309 - val_loss: 0.5673 - val_accuracy: 0.7083\n",
      "Epoch 109/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5536 - accuracy: 0.7309 - val_loss: 0.5668 - val_accuracy: 0.7083\n",
      "Epoch 110/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5530 - accuracy: 0.7309 - val_loss: 0.5663 - val_accuracy: 0.7083\n",
      "Epoch 111/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5523 - accuracy: 0.7309 - val_loss: 0.5658 - val_accuracy: 0.7083\n",
      "Epoch 112/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5517 - accuracy: 0.7309 - val_loss: 0.5654 - val_accuracy: 0.7083\n",
      "Epoch 113/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 38us/step - loss: 0.5511 - accuracy: 0.7309 - val_loss: 0.5649 - val_accuracy: 0.7083\n",
      "Epoch 114/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5505 - accuracy: 0.7309 - val_loss: 0.5644 - val_accuracy: 0.7083\n",
      "Epoch 115/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5499 - accuracy: 0.7344 - val_loss: 0.5640 - val_accuracy: 0.7083\n",
      "Epoch 116/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5493 - accuracy: 0.7344 - val_loss: 0.5635 - val_accuracy: 0.7083\n",
      "Epoch 117/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.5487 - accuracy: 0.7344 - val_loss: 0.5631 - val_accuracy: 0.7031\n",
      "Epoch 118/1500\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5481 - accuracy: 0.7361 - val_loss: 0.5626 - val_accuracy: 0.7031\n",
      "Epoch 119/1500\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.5476 - accuracy: 0.7344 - val_loss: 0.5622 - val_accuracy: 0.7031\n",
      "Epoch 120/1500\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5469 - accuracy: 0.7378 - val_loss: 0.5617 - val_accuracy: 0.7031\n",
      "Epoch 121/1500\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.5463 - accuracy: 0.7378 - val_loss: 0.5613 - val_accuracy: 0.7031\n",
      "Epoch 122/1500\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.5457 - accuracy: 0.7396 - val_loss: 0.5608 - val_accuracy: 0.7031\n",
      "Epoch 123/1500\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.5452 - accuracy: 0.7413 - val_loss: 0.5604 - val_accuracy: 0.7031\n",
      "Epoch 124/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.5446 - accuracy: 0.7413 - val_loss: 0.5600 - val_accuracy: 0.7031\n",
      "Epoch 125/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5440 - accuracy: 0.7413 - val_loss: 0.5595 - val_accuracy: 0.7031\n",
      "Epoch 126/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5435 - accuracy: 0.7413 - val_loss: 0.5591 - val_accuracy: 0.7031\n",
      "Epoch 127/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5429 - accuracy: 0.7431 - val_loss: 0.5587 - val_accuracy: 0.7031\n",
      "Epoch 128/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5424 - accuracy: 0.7431 - val_loss: 0.5583 - val_accuracy: 0.7031\n",
      "Epoch 129/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5419 - accuracy: 0.7448 - val_loss: 0.5579 - val_accuracy: 0.7031\n",
      "Epoch 130/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5414 - accuracy: 0.7448 - val_loss: 0.5575 - val_accuracy: 0.7031\n",
      "Epoch 131/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5409 - accuracy: 0.7431 - val_loss: 0.5571 - val_accuracy: 0.6979\n",
      "Epoch 132/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5404 - accuracy: 0.7431 - val_loss: 0.5567 - val_accuracy: 0.6979\n",
      "Epoch 133/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5398 - accuracy: 0.7431 - val_loss: 0.5563 - val_accuracy: 0.6979\n",
      "Epoch 134/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.5394 - accuracy: 0.7431 - val_loss: 0.5559 - val_accuracy: 0.6979\n",
      "Epoch 135/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5388 - accuracy: 0.7448 - val_loss: 0.5556 - val_accuracy: 0.6979\n",
      "Epoch 136/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5384 - accuracy: 0.7431 - val_loss: 0.5552 - val_accuracy: 0.6979\n",
      "Epoch 137/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5379 - accuracy: 0.7431 - val_loss: 0.5548 - val_accuracy: 0.6979\n",
      "Epoch 138/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.5374 - accuracy: 0.7413 - val_loss: 0.5544 - val_accuracy: 0.6979\n",
      "Epoch 139/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5369 - accuracy: 0.7448 - val_loss: 0.5541 - val_accuracy: 0.6979\n",
      "Epoch 140/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5365 - accuracy: 0.7431 - val_loss: 0.5537 - val_accuracy: 0.6979\n",
      "Epoch 141/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5360 - accuracy: 0.7431 - val_loss: 0.5534 - val_accuracy: 0.6979\n",
      "Epoch 142/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5355 - accuracy: 0.7431 - val_loss: 0.5530 - val_accuracy: 0.7031\n",
      "Epoch 143/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5351 - accuracy: 0.7448 - val_loss: 0.5527 - val_accuracy: 0.7031\n",
      "Epoch 144/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5347 - accuracy: 0.7448 - val_loss: 0.5524 - val_accuracy: 0.7031\n",
      "Epoch 145/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5342 - accuracy: 0.7448 - val_loss: 0.5520 - val_accuracy: 0.7031\n",
      "Epoch 146/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5338 - accuracy: 0.7483 - val_loss: 0.5517 - val_accuracy: 0.7031\n",
      "Epoch 147/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5333 - accuracy: 0.7448 - val_loss: 0.5514 - val_accuracy: 0.7031\n",
      "Epoch 148/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5329 - accuracy: 0.7465 - val_loss: 0.5510 - val_accuracy: 0.7031\n",
      "Epoch 149/1500\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.5325 - accuracy: 0.7448 - val_loss: 0.5507 - val_accuracy: 0.7031\n",
      "Epoch 150/1500\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.5320 - accuracy: 0.7465 - val_loss: 0.5504 - val_accuracy: 0.7031\n",
      "Epoch 151/1500\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.5316 - accuracy: 0.7465 - val_loss: 0.5501 - val_accuracy: 0.6979\n",
      "Epoch 152/1500\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.5312 - accuracy: 0.7465 - val_loss: 0.5498 - val_accuracy: 0.6979\n",
      "Epoch 153/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5308 - accuracy: 0.7483 - val_loss: 0.5495 - val_accuracy: 0.6979\n",
      "Epoch 154/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5304 - accuracy: 0.7465 - val_loss: 0.5492 - val_accuracy: 0.6927\n",
      "Epoch 155/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5299 - accuracy: 0.7483 - val_loss: 0.5489 - val_accuracy: 0.6927\n",
      "Epoch 156/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.5295 - accuracy: 0.7448 - val_loss: 0.5486 - val_accuracy: 0.6927\n",
      "Epoch 157/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5291 - accuracy: 0.7483 - val_loss: 0.5483 - val_accuracy: 0.6927\n",
      "Epoch 158/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5287 - accuracy: 0.7465 - val_loss: 0.5480 - val_accuracy: 0.6927\n",
      "Epoch 159/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5283 - accuracy: 0.7500 - val_loss: 0.5478 - val_accuracy: 0.6927\n",
      "Epoch 160/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5279 - accuracy: 0.7500 - val_loss: 0.5475 - val_accuracy: 0.6927\n",
      "Epoch 161/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5275 - accuracy: 0.7517 - val_loss: 0.5472 - val_accuracy: 0.6927\n",
      "Epoch 162/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5271 - accuracy: 0.7517 - val_loss: 0.5469 - val_accuracy: 0.6927\n",
      "Epoch 163/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5267 - accuracy: 0.7500 - val_loss: 0.5467 - val_accuracy: 0.6927\n",
      "Epoch 164/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5263 - accuracy: 0.7517 - val_loss: 0.5464 - val_accuracy: 0.6927\n",
      "Epoch 165/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5260 - accuracy: 0.7517 - val_loss: 0.5462 - val_accuracy: 0.6927\n",
      "Epoch 166/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5256 - accuracy: 0.7517 - val_loss: 0.5459 - val_accuracy: 0.6927\n",
      "Epoch 167/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5252 - accuracy: 0.7517 - val_loss: 0.5456 - val_accuracy: 0.6927\n",
      "Epoch 168/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5248 - accuracy: 0.7500 - val_loss: 0.5454 - val_accuracy: 0.6927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5245 - accuracy: 0.7500 - val_loss: 0.5451 - val_accuracy: 0.6927\n",
      "Epoch 170/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5241 - accuracy: 0.7500 - val_loss: 0.5449 - val_accuracy: 0.6927\n",
      "Epoch 171/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.5237 - accuracy: 0.7483 - val_loss: 0.5447 - val_accuracy: 0.6927\n",
      "Epoch 172/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5233 - accuracy: 0.7465 - val_loss: 0.5444 - val_accuracy: 0.6927\n",
      "Epoch 173/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5230 - accuracy: 0.7465 - val_loss: 0.5442 - val_accuracy: 0.6927\n",
      "Epoch 174/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5226 - accuracy: 0.7465 - val_loss: 0.5440 - val_accuracy: 0.6927\n",
      "Epoch 175/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.5222 - accuracy: 0.7465 - val_loss: 0.5438 - val_accuracy: 0.6927\n",
      "Epoch 176/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5219 - accuracy: 0.7483 - val_loss: 0.5436 - val_accuracy: 0.6927\n",
      "Epoch 177/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5215 - accuracy: 0.7500 - val_loss: 0.5433 - val_accuracy: 0.6927\n",
      "Epoch 178/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.5212 - accuracy: 0.7500 - val_loss: 0.5431 - val_accuracy: 0.6927\n",
      "Epoch 179/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5208 - accuracy: 0.7500 - val_loss: 0.5429 - val_accuracy: 0.6979\n",
      "Epoch 180/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5204 - accuracy: 0.7500 - val_loss: 0.5427 - val_accuracy: 0.6979\n",
      "Epoch 181/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5200 - accuracy: 0.7500 - val_loss: 0.5425 - val_accuracy: 0.6979\n",
      "Epoch 182/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5196 - accuracy: 0.7517 - val_loss: 0.5422 - val_accuracy: 0.6979\n",
      "Epoch 183/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5192 - accuracy: 0.7517 - val_loss: 0.5420 - val_accuracy: 0.6927\n",
      "Epoch 184/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5188 - accuracy: 0.7535 - val_loss: 0.5418 - val_accuracy: 0.6927\n",
      "Epoch 185/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5184 - accuracy: 0.7517 - val_loss: 0.5416 - val_accuracy: 0.6927\n",
      "Epoch 186/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5180 - accuracy: 0.7517 - val_loss: 0.5413 - val_accuracy: 0.6927\n",
      "Epoch 187/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5176 - accuracy: 0.7517 - val_loss: 0.5411 - val_accuracy: 0.6927\n",
      "Epoch 188/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5171 - accuracy: 0.7535 - val_loss: 0.5409 - val_accuracy: 0.6927\n",
      "Epoch 189/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5167 - accuracy: 0.7517 - val_loss: 0.5407 - val_accuracy: 0.6927\n",
      "Epoch 190/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5163 - accuracy: 0.7535 - val_loss: 0.5405 - val_accuracy: 0.6927\n",
      "Epoch 191/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5160 - accuracy: 0.7535 - val_loss: 0.5402 - val_accuracy: 0.6927\n",
      "Epoch 192/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5155 - accuracy: 0.7552 - val_loss: 0.5400 - val_accuracy: 0.6979\n",
      "Epoch 193/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5152 - accuracy: 0.7535 - val_loss: 0.5398 - val_accuracy: 0.6979\n",
      "Epoch 194/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5148 - accuracy: 0.7552 - val_loss: 0.5396 - val_accuracy: 0.6979\n",
      "Epoch 195/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5144 - accuracy: 0.7535 - val_loss: 0.5394 - val_accuracy: 0.6979\n",
      "Epoch 196/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5140 - accuracy: 0.7535 - val_loss: 0.5392 - val_accuracy: 0.6979\n",
      "Epoch 197/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5136 - accuracy: 0.7535 - val_loss: 0.5390 - val_accuracy: 0.6979\n",
      "Epoch 198/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5132 - accuracy: 0.7535 - val_loss: 0.5388 - val_accuracy: 0.7031\n",
      "Epoch 199/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5129 - accuracy: 0.7552 - val_loss: 0.5385 - val_accuracy: 0.7031\n",
      "Epoch 200/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5124 - accuracy: 0.7535 - val_loss: 0.5383 - val_accuracy: 0.7031\n",
      "Epoch 201/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5121 - accuracy: 0.7517 - val_loss: 0.5381 - val_accuracy: 0.7031\n",
      "Epoch 202/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5117 - accuracy: 0.7517 - val_loss: 0.5379 - val_accuracy: 0.7031\n",
      "Epoch 203/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5113 - accuracy: 0.7552 - val_loss: 0.5377 - val_accuracy: 0.7031\n",
      "Epoch 204/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5109 - accuracy: 0.7552 - val_loss: 0.5375 - val_accuracy: 0.7031\n",
      "Epoch 205/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5105 - accuracy: 0.7552 - val_loss: 0.5373 - val_accuracy: 0.7031\n",
      "Epoch 206/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5101 - accuracy: 0.7552 - val_loss: 0.5371 - val_accuracy: 0.7031\n",
      "Epoch 207/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5098 - accuracy: 0.7552 - val_loss: 0.5369 - val_accuracy: 0.7083\n",
      "Epoch 208/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5094 - accuracy: 0.7552 - val_loss: 0.5367 - val_accuracy: 0.7083\n",
      "Epoch 209/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5090 - accuracy: 0.7535 - val_loss: 0.5365 - val_accuracy: 0.7083\n",
      "Epoch 210/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.5087 - accuracy: 0.7552 - val_loss: 0.5363 - val_accuracy: 0.7083\n",
      "Epoch 211/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.5083 - accuracy: 0.7552 - val_loss: 0.5362 - val_accuracy: 0.7083\n",
      "Epoch 212/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5079 - accuracy: 0.7552 - val_loss: 0.5360 - val_accuracy: 0.7083\n",
      "Epoch 213/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5076 - accuracy: 0.7552 - val_loss: 0.5358 - val_accuracy: 0.7083\n",
      "Epoch 214/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.5072 - accuracy: 0.7569 - val_loss: 0.5356 - val_accuracy: 0.7083\n",
      "Epoch 215/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5069 - accuracy: 0.7569 - val_loss: 0.5354 - val_accuracy: 0.7083\n",
      "Epoch 216/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5065 - accuracy: 0.7569 - val_loss: 0.5353 - val_accuracy: 0.7083\n",
      "Epoch 217/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5061 - accuracy: 0.7569 - val_loss: 0.5351 - val_accuracy: 0.7083\n",
      "Epoch 218/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5058 - accuracy: 0.7569 - val_loss: 0.5349 - val_accuracy: 0.7083\n",
      "Epoch 219/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5054 - accuracy: 0.7552 - val_loss: 0.5347 - val_accuracy: 0.7083\n",
      "Epoch 220/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5051 - accuracy: 0.7569 - val_loss: 0.5345 - val_accuracy: 0.7083\n",
      "Epoch 221/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5047 - accuracy: 0.7552 - val_loss: 0.5344 - val_accuracy: 0.7083\n",
      "Epoch 222/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.5044 - accuracy: 0.7569 - val_loss: 0.5342 - val_accuracy: 0.7083\n",
      "Epoch 223/1500\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5040 - accuracy: 0.7587 - val_loss: 0.5340 - val_accuracy: 0.7083\n",
      "Epoch 224/1500\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.5037 - accuracy: 0.7569 - val_loss: 0.5338 - val_accuracy: 0.7083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1500\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5034 - accuracy: 0.7587 - val_loss: 0.5337 - val_accuracy: 0.7083\n",
      "Epoch 226/1500\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.5030 - accuracy: 0.7587 - val_loss: 0.5335 - val_accuracy: 0.7083\n",
      "Epoch 227/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5027 - accuracy: 0.7587 - val_loss: 0.5334 - val_accuracy: 0.7083\n",
      "Epoch 228/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.5023 - accuracy: 0.7569 - val_loss: 0.5332 - val_accuracy: 0.7135\n",
      "Epoch 229/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5020 - accuracy: 0.7587 - val_loss: 0.5330 - val_accuracy: 0.7188\n",
      "Epoch 230/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5017 - accuracy: 0.7552 - val_loss: 0.5329 - val_accuracy: 0.7188\n",
      "Epoch 231/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5014 - accuracy: 0.7552 - val_loss: 0.5327 - val_accuracy: 0.7188\n",
      "Epoch 232/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5010 - accuracy: 0.7569 - val_loss: 0.5325 - val_accuracy: 0.7188\n",
      "Epoch 233/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5007 - accuracy: 0.7569 - val_loss: 0.5324 - val_accuracy: 0.7188\n",
      "Epoch 234/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5004 - accuracy: 0.7552 - val_loss: 0.5322 - val_accuracy: 0.7188\n",
      "Epoch 235/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5000 - accuracy: 0.7569 - val_loss: 0.5321 - val_accuracy: 0.7188\n",
      "Epoch 236/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4998 - accuracy: 0.7569 - val_loss: 0.5319 - val_accuracy: 0.7188\n",
      "Epoch 237/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4994 - accuracy: 0.7569 - val_loss: 0.5317 - val_accuracy: 0.7188\n",
      "Epoch 238/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4991 - accuracy: 0.7569 - val_loss: 0.5316 - val_accuracy: 0.7188\n",
      "Epoch 239/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4988 - accuracy: 0.7569 - val_loss: 0.5315 - val_accuracy: 0.7240\n",
      "Epoch 240/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4986 - accuracy: 0.7569 - val_loss: 0.5313 - val_accuracy: 0.7240\n",
      "Epoch 241/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4983 - accuracy: 0.7569 - val_loss: 0.5312 - val_accuracy: 0.7240\n",
      "Epoch 242/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4980 - accuracy: 0.7569 - val_loss: 0.5311 - val_accuracy: 0.7240\n",
      "Epoch 243/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4976 - accuracy: 0.7569 - val_loss: 0.5310 - val_accuracy: 0.7240\n",
      "Epoch 244/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4974 - accuracy: 0.7569 - val_loss: 0.5309 - val_accuracy: 0.7240\n",
      "Epoch 245/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4971 - accuracy: 0.7569 - val_loss: 0.5307 - val_accuracy: 0.7240\n",
      "Epoch 246/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4968 - accuracy: 0.7569 - val_loss: 0.5306 - val_accuracy: 0.7240\n",
      "Epoch 247/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4966 - accuracy: 0.7569 - val_loss: 0.5305 - val_accuracy: 0.7240\n",
      "Epoch 248/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4963 - accuracy: 0.7569 - val_loss: 0.5304 - val_accuracy: 0.7240\n",
      "Epoch 249/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4960 - accuracy: 0.7569 - val_loss: 0.5303 - val_accuracy: 0.7240\n",
      "Epoch 250/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4958 - accuracy: 0.7569 - val_loss: 0.5302 - val_accuracy: 0.7240\n",
      "Epoch 251/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4955 - accuracy: 0.7569 - val_loss: 0.5301 - val_accuracy: 0.7240\n",
      "Epoch 252/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4952 - accuracy: 0.7569 - val_loss: 0.5300 - val_accuracy: 0.7240\n",
      "Epoch 253/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4949 - accuracy: 0.7569 - val_loss: 0.5299 - val_accuracy: 0.7240\n",
      "Epoch 254/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4947 - accuracy: 0.7569 - val_loss: 0.5298 - val_accuracy: 0.7240\n",
      "Epoch 255/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4944 - accuracy: 0.7587 - val_loss: 0.5297 - val_accuracy: 0.7240\n",
      "Epoch 256/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4942 - accuracy: 0.7587 - val_loss: 0.5296 - val_accuracy: 0.7240\n",
      "Epoch 257/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4939 - accuracy: 0.7587 - val_loss: 0.5295 - val_accuracy: 0.7240\n",
      "Epoch 258/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4937 - accuracy: 0.7587 - val_loss: 0.5294 - val_accuracy: 0.7240\n",
      "Epoch 259/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4934 - accuracy: 0.7587 - val_loss: 0.5293 - val_accuracy: 0.7240\n",
      "Epoch 260/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4931 - accuracy: 0.7569 - val_loss: 0.5292 - val_accuracy: 0.7240\n",
      "Epoch 261/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4686 - accuracy: 0.81 - 0s 43us/step - loss: 0.4928 - accuracy: 0.7587 - val_loss: 0.5291 - val_accuracy: 0.7240\n",
      "Epoch 262/1500\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4926 - accuracy: 0.7587 - val_loss: 0.5290 - val_accuracy: 0.7240\n",
      "Epoch 263/1500\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4924 - accuracy: 0.7569 - val_loss: 0.5289 - val_accuracy: 0.7188\n",
      "Epoch 264/1500\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4921 - accuracy: 0.7569 - val_loss: 0.5288 - val_accuracy: 0.7240\n",
      "Epoch 265/1500\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4918 - accuracy: 0.7569 - val_loss: 0.5288 - val_accuracy: 0.7240\n",
      "Epoch 266/1500\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4916 - accuracy: 0.7587 - val_loss: 0.5287 - val_accuracy: 0.7240\n",
      "Epoch 267/1500\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4913 - accuracy: 0.7587 - val_loss: 0.5286 - val_accuracy: 0.7240\n",
      "Epoch 268/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4911 - accuracy: 0.7587 - val_loss: 0.5285 - val_accuracy: 0.7240\n",
      "Epoch 269/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4908 - accuracy: 0.7587 - val_loss: 0.5284 - val_accuracy: 0.7240\n",
      "Epoch 270/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4906 - accuracy: 0.7587 - val_loss: 0.5283 - val_accuracy: 0.7240\n",
      "Epoch 271/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4903 - accuracy: 0.7587 - val_loss: 0.5282 - val_accuracy: 0.7240\n",
      "Epoch 272/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4901 - accuracy: 0.7587 - val_loss: 0.5281 - val_accuracy: 0.7240\n",
      "Epoch 273/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4899 - accuracy: 0.7587 - val_loss: 0.5280 - val_accuracy: 0.7240\n",
      "Epoch 274/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4897 - accuracy: 0.7587 - val_loss: 0.5279 - val_accuracy: 0.7240\n",
      "Epoch 275/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4895 - accuracy: 0.7587 - val_loss: 0.5278 - val_accuracy: 0.7240\n",
      "Epoch 276/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4892 - accuracy: 0.7587 - val_loss: 0.5277 - val_accuracy: 0.7240\n",
      "Epoch 277/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4890 - accuracy: 0.7587 - val_loss: 0.5276 - val_accuracy: 0.7240\n",
      "Epoch 278/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4888 - accuracy: 0.7587 - val_loss: 0.5275 - val_accuracy: 0.7240\n",
      "Epoch 279/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4886 - accuracy: 0.7604 - val_loss: 0.5274 - val_accuracy: 0.7240\n",
      "Epoch 280/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4883 - accuracy: 0.7622 - val_loss: 0.5273 - val_accuracy: 0.7240\n",
      "Epoch 281/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4881 - accuracy: 0.7604 - val_loss: 0.5271 - val_accuracy: 0.7240\n",
      "Epoch 282/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4879 - accuracy: 0.7604 - val_loss: 0.5270 - val_accuracy: 0.7240\n",
      "Epoch 283/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4876 - accuracy: 0.7604 - val_loss: 0.5269 - val_accuracy: 0.7240\n",
      "Epoch 284/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3692 - accuracy: 0.84 - 0s 43us/step - loss: 0.4874 - accuracy: 0.7604 - val_loss: 0.5268 - val_accuracy: 0.7240\n",
      "Epoch 285/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4872 - accuracy: 0.7604 - val_loss: 0.5267 - val_accuracy: 0.7188\n",
      "Epoch 286/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4870 - accuracy: 0.7604 - val_loss: 0.5267 - val_accuracy: 0.7188\n",
      "Epoch 287/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4867 - accuracy: 0.7604 - val_loss: 0.5266 - val_accuracy: 0.7188\n",
      "Epoch 288/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4865 - accuracy: 0.7622 - val_loss: 0.5265 - val_accuracy: 0.7188\n",
      "Epoch 289/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4863 - accuracy: 0.7622 - val_loss: 0.5264 - val_accuracy: 0.7188\n",
      "Epoch 290/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4861 - accuracy: 0.7604 - val_loss: 0.5263 - val_accuracy: 0.7188\n",
      "Epoch 291/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4859 - accuracy: 0.7604 - val_loss: 0.5262 - val_accuracy: 0.7188\n",
      "Epoch 292/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4857 - accuracy: 0.7604 - val_loss: 0.5261 - val_accuracy: 0.7188\n",
      "Epoch 293/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4855 - accuracy: 0.7604 - val_loss: 0.5260 - val_accuracy: 0.7188\n",
      "Epoch 294/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4852 - accuracy: 0.7604 - val_loss: 0.5259 - val_accuracy: 0.7188\n",
      "Epoch 295/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4850 - accuracy: 0.7604 - val_loss: 0.5259 - val_accuracy: 0.7188\n",
      "Epoch 296/1500\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4848 - accuracy: 0.7587 - val_loss: 0.5258 - val_accuracy: 0.7188\n",
      "Epoch 297/1500\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4845 - accuracy: 0.7587 - val_loss: 0.5257 - val_accuracy: 0.7188\n",
      "Epoch 298/1500\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4843 - accuracy: 0.7587 - val_loss: 0.5256 - val_accuracy: 0.7188\n",
      "Epoch 299/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4841 - accuracy: 0.7604 - val_loss: 0.5255 - val_accuracy: 0.7188\n",
      "Epoch 300/1500\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4839 - accuracy: 0.7622 - val_loss: 0.5254 - val_accuracy: 0.7188\n",
      "Epoch 301/1500\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4837 - accuracy: 0.7604 - val_loss: 0.5254 - val_accuracy: 0.7188\n",
      "Epoch 302/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4834 - accuracy: 0.7604 - val_loss: 0.5253 - val_accuracy: 0.7188\n",
      "Epoch 303/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4832 - accuracy: 0.7622 - val_loss: 0.5252 - val_accuracy: 0.7188\n",
      "Epoch 304/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4829 - accuracy: 0.7604 - val_loss: 0.5251 - val_accuracy: 0.7240\n",
      "Epoch 305/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4827 - accuracy: 0.7622 - val_loss: 0.5250 - val_accuracy: 0.7240\n",
      "Epoch 306/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4825 - accuracy: 0.7604 - val_loss: 0.5249 - val_accuracy: 0.7240\n",
      "Epoch 307/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4822 - accuracy: 0.7604 - val_loss: 0.5248 - val_accuracy: 0.7240\n",
      "Epoch 308/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4820 - accuracy: 0.7604 - val_loss: 0.5248 - val_accuracy: 0.7240\n",
      "Epoch 309/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4819 - accuracy: 0.7604 - val_loss: 0.5247 - val_accuracy: 0.7240\n",
      "Epoch 310/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4816 - accuracy: 0.7622 - val_loss: 0.5246 - val_accuracy: 0.7240\n",
      "Epoch 311/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4815 - accuracy: 0.7604 - val_loss: 0.5245 - val_accuracy: 0.7240\n",
      "Epoch 312/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4812 - accuracy: 0.7622 - val_loss: 0.5245 - val_accuracy: 0.7240\n",
      "Epoch 313/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4810 - accuracy: 0.7604 - val_loss: 0.5244 - val_accuracy: 0.7240\n",
      "Epoch 314/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4808 - accuracy: 0.7604 - val_loss: 0.5243 - val_accuracy: 0.7240\n",
      "Epoch 315/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4806 - accuracy: 0.7587 - val_loss: 0.5242 - val_accuracy: 0.7240\n",
      "Epoch 316/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4804 - accuracy: 0.7604 - val_loss: 0.5241 - val_accuracy: 0.7240\n",
      "Epoch 317/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4801 - accuracy: 0.7604 - val_loss: 0.5240 - val_accuracy: 0.7240\n",
      "Epoch 318/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4799 - accuracy: 0.7587 - val_loss: 0.5240 - val_accuracy: 0.7240\n",
      "Epoch 319/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4797 - accuracy: 0.7604 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
      "Epoch 320/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4795 - accuracy: 0.7604 - val_loss: 0.5238 - val_accuracy: 0.7240\n",
      "Epoch 321/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.6111 - accuracy: 0.59 - 0s 48us/step - loss: 0.4792 - accuracy: 0.7604 - val_loss: 0.5237 - val_accuracy: 0.7240\n",
      "Epoch 322/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4790 - accuracy: 0.7587 - val_loss: 0.5237 - val_accuracy: 0.7240\n",
      "Epoch 323/1500\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4788 - accuracy: 0.7604 - val_loss: 0.5236 - val_accuracy: 0.7240\n",
      "Epoch 324/1500\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4786 - accuracy: 0.7604 - val_loss: 0.5235 - val_accuracy: 0.7240\n",
      "Epoch 325/1500\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4784 - accuracy: 0.7604 - val_loss: 0.5234 - val_accuracy: 0.7240\n",
      "Epoch 326/1500\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.4782 - accuracy: 0.7604 - val_loss: 0.5233 - val_accuracy: 0.7240\n",
      "Epoch 327/1500\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4780 - accuracy: 0.7604 - val_loss: 0.5233 - val_accuracy: 0.7240\n",
      "Epoch 328/1500\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4778 - accuracy: 0.7587 - val_loss: 0.5232 - val_accuracy: 0.7240\n",
      "Epoch 329/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4777 - accuracy: 0.7622 - val_loss: 0.5231 - val_accuracy: 0.7240\n",
      "Epoch 330/1500\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4774 - accuracy: 0.7622 - val_loss: 0.5231 - val_accuracy: 0.7240\n",
      "Epoch 331/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4772 - accuracy: 0.7622 - val_loss: 0.5230 - val_accuracy: 0.7240\n",
      "Epoch 332/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4771 - accuracy: 0.7622 - val_loss: 0.5229 - val_accuracy: 0.7240\n",
      "Epoch 333/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4768 - accuracy: 0.7622 - val_loss: 0.5229 - val_accuracy: 0.7240\n",
      "Epoch 334/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4767 - accuracy: 0.7622 - val_loss: 0.5228 - val_accuracy: 0.7240\n",
      "Epoch 335/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 45us/step - loss: 0.4765 - accuracy: 0.7622 - val_loss: 0.5227 - val_accuracy: 0.7240\n",
      "Epoch 336/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4763 - accuracy: 0.7622 - val_loss: 0.5226 - val_accuracy: 0.7240\n",
      "Epoch 337/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4761 - accuracy: 0.7622 - val_loss: 0.5226 - val_accuracy: 0.7292\n",
      "Epoch 338/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4759 - accuracy: 0.7622 - val_loss: 0.5225 - val_accuracy: 0.7292\n",
      "Epoch 339/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4758 - accuracy: 0.7622 - val_loss: 0.5224 - val_accuracy: 0.7292\n",
      "Epoch 340/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4756 - accuracy: 0.7622 - val_loss: 0.5223 - val_accuracy: 0.7292\n",
      "Epoch 341/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4754 - accuracy: 0.7622 - val_loss: 0.5222 - val_accuracy: 0.7292\n",
      "Epoch 342/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4752 - accuracy: 0.7622 - val_loss: 0.5222 - val_accuracy: 0.7292\n",
      "Epoch 343/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4751 - accuracy: 0.7622 - val_loss: 0.5221 - val_accuracy: 0.7292\n",
      "Epoch 344/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4749 - accuracy: 0.7622 - val_loss: 0.5220 - val_accuracy: 0.7292\n",
      "Epoch 345/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4747 - accuracy: 0.7622 - val_loss: 0.5219 - val_accuracy: 0.7292\n",
      "Epoch 346/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4746 - accuracy: 0.7622 - val_loss: 0.5219 - val_accuracy: 0.7292\n",
      "Epoch 347/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4744 - accuracy: 0.7622 - val_loss: 0.5218 - val_accuracy: 0.7292\n",
      "Epoch 348/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4742 - accuracy: 0.7622 - val_loss: 0.5217 - val_accuracy: 0.7292\n",
      "Epoch 349/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4741 - accuracy: 0.7622 - val_loss: 0.5216 - val_accuracy: 0.7292\n",
      "Epoch 350/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4740 - accuracy: 0.7622 - val_loss: 0.5215 - val_accuracy: 0.7292\n",
      "Epoch 351/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4738 - accuracy: 0.7622 - val_loss: 0.5215 - val_accuracy: 0.7292\n",
      "Epoch 352/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4737 - accuracy: 0.7639 - val_loss: 0.5214 - val_accuracy: 0.7292\n",
      "Epoch 353/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4735 - accuracy: 0.7622 - val_loss: 0.5213 - val_accuracy: 0.7292\n",
      "Epoch 354/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4733 - accuracy: 0.7622 - val_loss: 0.5212 - val_accuracy: 0.7292\n",
      "Epoch 355/1500\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4732 - accuracy: 0.7622 - val_loss: 0.5211 - val_accuracy: 0.7292\n",
      "Epoch 356/1500\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4731 - accuracy: 0.7622 - val_loss: 0.5211 - val_accuracy: 0.7292\n",
      "Epoch 357/1500\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4729 - accuracy: 0.7622 - val_loss: 0.5210 - val_accuracy: 0.7292\n",
      "Epoch 358/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4728 - accuracy: 0.7622 - val_loss: 0.5209 - val_accuracy: 0.7292\n",
      "Epoch 359/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4727 - accuracy: 0.7622 - val_loss: 0.5209 - val_accuracy: 0.7292\n",
      "Epoch 360/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4725 - accuracy: 0.7622 - val_loss: 0.5208 - val_accuracy: 0.7292\n",
      "Epoch 361/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4723 - accuracy: 0.7622 - val_loss: 0.5207 - val_accuracy: 0.7292\n",
      "Epoch 362/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4722 - accuracy: 0.7622 - val_loss: 0.5206 - val_accuracy: 0.7292\n",
      "Epoch 363/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4720 - accuracy: 0.7622 - val_loss: 0.5206 - val_accuracy: 0.7292\n",
      "Epoch 364/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4719 - accuracy: 0.7622 - val_loss: 0.5205 - val_accuracy: 0.7292\n",
      "Epoch 365/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4717 - accuracy: 0.7622 - val_loss: 0.5204 - val_accuracy: 0.7292\n",
      "Epoch 366/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4716 - accuracy: 0.7622 - val_loss: 0.5203 - val_accuracy: 0.7292\n",
      "Epoch 367/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4715 - accuracy: 0.7622 - val_loss: 0.5202 - val_accuracy: 0.7292\n",
      "Epoch 368/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4713 - accuracy: 0.7622 - val_loss: 0.5202 - val_accuracy: 0.7292\n",
      "Epoch 369/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4712 - accuracy: 0.7604 - val_loss: 0.5201 - val_accuracy: 0.7292\n",
      "Epoch 370/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4710 - accuracy: 0.7604 - val_loss: 0.5200 - val_accuracy: 0.7292\n",
      "Epoch 371/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4709 - accuracy: 0.7622 - val_loss: 0.5200 - val_accuracy: 0.7292\n",
      "Epoch 372/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4708 - accuracy: 0.7622 - val_loss: 0.5199 - val_accuracy: 0.7292\n",
      "Epoch 373/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4706 - accuracy: 0.7622 - val_loss: 0.5198 - val_accuracy: 0.7292\n",
      "Epoch 374/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4705 - accuracy: 0.7622 - val_loss: 0.5198 - val_accuracy: 0.7292\n",
      "Epoch 375/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4703 - accuracy: 0.7622 - val_loss: 0.5197 - val_accuracy: 0.7292\n",
      "Epoch 376/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4702 - accuracy: 0.7622 - val_loss: 0.5196 - val_accuracy: 0.7292\n",
      "Epoch 377/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4700 - accuracy: 0.7622 - val_loss: 0.5195 - val_accuracy: 0.7292\n",
      "Epoch 378/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4699 - accuracy: 0.7622 - val_loss: 0.5195 - val_accuracy: 0.7292\n",
      "Epoch 379/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4698 - accuracy: 0.7622 - val_loss: 0.5194 - val_accuracy: 0.7292\n",
      "Epoch 380/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4697 - accuracy: 0.7639 - val_loss: 0.5193 - val_accuracy: 0.7292\n",
      "Epoch 381/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4695 - accuracy: 0.7639 - val_loss: 0.5193 - val_accuracy: 0.7292\n",
      "Epoch 382/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4694 - accuracy: 0.7639 - val_loss: 0.5192 - val_accuracy: 0.7292\n",
      "Epoch 383/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4692 - accuracy: 0.7639 - val_loss: 0.5191 - val_accuracy: 0.7344\n",
      "Epoch 384/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4691 - accuracy: 0.7656 - val_loss: 0.5191 - val_accuracy: 0.7344\n",
      "Epoch 385/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4690 - accuracy: 0.7656 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 386/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4688 - accuracy: 0.7656 - val_loss: 0.5189 - val_accuracy: 0.7344\n",
      "Epoch 387/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4687 - accuracy: 0.7656 - val_loss: 0.5189 - val_accuracy: 0.7344\n",
      "Epoch 388/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4686 - accuracy: 0.7656 - val_loss: 0.5188 - val_accuracy: 0.7344\n",
      "Epoch 389/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4685 - accuracy: 0.7656 - val_loss: 0.5187 - val_accuracy: 0.7344\n",
      "Epoch 390/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4683 - accuracy: 0.7674 - val_loss: 0.5186 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4682 - accuracy: 0.7674 - val_loss: 0.5186 - val_accuracy: 0.7344\n",
      "Epoch 392/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4680 - accuracy: 0.7674 - val_loss: 0.5185 - val_accuracy: 0.7344\n",
      "Epoch 393/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4679 - accuracy: 0.7691 - val_loss: 0.5185 - val_accuracy: 0.7344\n",
      "Epoch 394/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4678 - accuracy: 0.7691 - val_loss: 0.5184 - val_accuracy: 0.7344\n",
      "Epoch 395/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4677 - accuracy: 0.7674 - val_loss: 0.5183 - val_accuracy: 0.7344\n",
      "Epoch 396/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4675 - accuracy: 0.7708 - val_loss: 0.5183 - val_accuracy: 0.7344\n",
      "Epoch 397/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4674 - accuracy: 0.7708 - val_loss: 0.5182 - val_accuracy: 0.7344\n",
      "Epoch 398/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4672 - accuracy: 0.7691 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 399/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4671 - accuracy: 0.7691 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 400/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4670 - accuracy: 0.7691 - val_loss: 0.5180 - val_accuracy: 0.7344\n",
      "Epoch 401/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4668 - accuracy: 0.7691 - val_loss: 0.5179 - val_accuracy: 0.7344\n",
      "Epoch 402/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4667 - accuracy: 0.7691 - val_loss: 0.5179 - val_accuracy: 0.7344\n",
      "Epoch 403/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4665 - accuracy: 0.7708 - val_loss: 0.5178 - val_accuracy: 0.7344\n",
      "Epoch 404/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4664 - accuracy: 0.7691 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 405/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4663 - accuracy: 0.7691 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 406/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4661 - accuracy: 0.7708 - val_loss: 0.5175 - val_accuracy: 0.7344\n",
      "Epoch 407/1500\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.4659 - accuracy: 0.7708 - val_loss: 0.5174 - val_accuracy: 0.7344\n",
      "Epoch 408/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4658 - accuracy: 0.7708 - val_loss: 0.5173 - val_accuracy: 0.7344\n",
      "Epoch 409/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4657 - accuracy: 0.7726 - val_loss: 0.5172 - val_accuracy: 0.7344\n",
      "Epoch 410/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4655 - accuracy: 0.7726 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 411/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4654 - accuracy: 0.7726 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 412/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4653 - accuracy: 0.7726 - val_loss: 0.5170 - val_accuracy: 0.7292\n",
      "Epoch 413/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4652 - accuracy: 0.7726 - val_loss: 0.5169 - val_accuracy: 0.7292\n",
      "Epoch 414/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4650 - accuracy: 0.7726 - val_loss: 0.5168 - val_accuracy: 0.7292\n",
      "Epoch 415/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4649 - accuracy: 0.7726 - val_loss: 0.5167 - val_accuracy: 0.7292\n",
      "Epoch 416/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4648 - accuracy: 0.7726 - val_loss: 0.5167 - val_accuracy: 0.7292\n",
      "Epoch 417/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4646 - accuracy: 0.7726 - val_loss: 0.5166 - val_accuracy: 0.7292\n",
      "Epoch 418/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4645 - accuracy: 0.7726 - val_loss: 0.5165 - val_accuracy: 0.7292\n",
      "Epoch 419/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4644 - accuracy: 0.7726 - val_loss: 0.5164 - val_accuracy: 0.7292\n",
      "Epoch 420/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4643 - accuracy: 0.7726 - val_loss: 0.5163 - val_accuracy: 0.7344\n",
      "Epoch 421/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4642 - accuracy: 0.7726 - val_loss: 0.5162 - val_accuracy: 0.7344\n",
      "Epoch 422/1500\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4640 - accuracy: 0.7726 - val_loss: 0.5161 - val_accuracy: 0.7344\n",
      "Epoch 423/1500\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4639 - accuracy: 0.7726 - val_loss: 0.5161 - val_accuracy: 0.7344\n",
      "Epoch 424/1500\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4638 - accuracy: 0.7726 - val_loss: 0.5160 - val_accuracy: 0.7344\n",
      "Epoch 425/1500\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4636 - accuracy: 0.7726 - val_loss: 0.5159 - val_accuracy: 0.7344\n",
      "Epoch 426/1500\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4635 - accuracy: 0.7726 - val_loss: 0.5159 - val_accuracy: 0.7344\n",
      "Epoch 427/1500\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4634 - accuracy: 0.7726 - val_loss: 0.5158 - val_accuracy: 0.7344\n",
      "Epoch 428/1500\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4633 - accuracy: 0.7726 - val_loss: 0.5158 - val_accuracy: 0.7344\n",
      "Epoch 429/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4632 - accuracy: 0.7726 - val_loss: 0.5157 - val_accuracy: 0.7344\n",
      "Epoch 430/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4630 - accuracy: 0.7726 - val_loss: 0.5157 - val_accuracy: 0.7344\n",
      "Epoch 431/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4629 - accuracy: 0.7726 - val_loss: 0.5156 - val_accuracy: 0.7344\n",
      "Epoch 432/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4628 - accuracy: 0.7726 - val_loss: 0.5155 - val_accuracy: 0.7344\n",
      "Epoch 433/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4627 - accuracy: 0.7726 - val_loss: 0.5155 - val_accuracy: 0.7344\n",
      "Epoch 434/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4625 - accuracy: 0.7726 - val_loss: 0.5154 - val_accuracy: 0.7344\n",
      "Epoch 435/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4625 - accuracy: 0.7726 - val_loss: 0.5154 - val_accuracy: 0.7344\n",
      "Epoch 436/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4623 - accuracy: 0.7726 - val_loss: 0.5153 - val_accuracy: 0.7344\n",
      "Epoch 437/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4622 - accuracy: 0.7726 - val_loss: 0.5153 - val_accuracy: 0.7344\n",
      "Epoch 438/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4621 - accuracy: 0.7726 - val_loss: 0.5152 - val_accuracy: 0.7344\n",
      "Epoch 439/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4620 - accuracy: 0.7708 - val_loss: 0.5152 - val_accuracy: 0.7396\n",
      "Epoch 440/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4619 - accuracy: 0.7691 - val_loss: 0.5152 - val_accuracy: 0.7396\n",
      "Epoch 441/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4618 - accuracy: 0.7691 - val_loss: 0.5151 - val_accuracy: 0.7396\n",
      "Epoch 442/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4617 - accuracy: 0.7708 - val_loss: 0.5151 - val_accuracy: 0.7396\n",
      "Epoch 443/1500\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4616 - accuracy: 0.7691 - val_loss: 0.5150 - val_accuracy: 0.7396\n",
      "Epoch 444/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4615 - accuracy: 0.7708 - val_loss: 0.5150 - val_accuracy: 0.7396\n",
      "Epoch 445/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4614 - accuracy: 0.7708 - val_loss: 0.5149 - val_accuracy: 0.7396\n",
      "Epoch 446/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4613 - accuracy: 0.7708 - val_loss: 0.5149 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 447/1500\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4612 - accuracy: 0.7743 - val_loss: 0.5149 - val_accuracy: 0.7396\n",
      "Epoch 448/1500\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4611 - accuracy: 0.7726 - val_loss: 0.5148 - val_accuracy: 0.7396\n",
      "Epoch 449/1500\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4610 - accuracy: 0.7726 - val_loss: 0.5148 - val_accuracy: 0.7396\n",
      "Epoch 450/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.2878 - accuracy: 0.87 - 0s 74us/step - loss: 0.4608 - accuracy: 0.7726 - val_loss: 0.5148 - val_accuracy: 0.7396\n",
      "Epoch 451/1500\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4607 - accuracy: 0.7743 - val_loss: 0.5147 - val_accuracy: 0.7396\n",
      "Epoch 452/1500\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.4606 - accuracy: 0.7743 - val_loss: 0.5147 - val_accuracy: 0.7396\n",
      "Epoch 453/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4605 - accuracy: 0.7743 - val_loss: 0.5146 - val_accuracy: 0.7396\n",
      "Epoch 454/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4604 - accuracy: 0.7726 - val_loss: 0.5146 - val_accuracy: 0.7396\n",
      "Epoch 455/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4603 - accuracy: 0.7743 - val_loss: 0.5145 - val_accuracy: 0.7396\n",
      "Epoch 456/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4602 - accuracy: 0.7743 - val_loss: 0.5145 - val_accuracy: 0.7396\n",
      "Epoch 457/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4601 - accuracy: 0.7708 - val_loss: 0.5145 - val_accuracy: 0.7396\n",
      "Epoch 458/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4600 - accuracy: 0.7726 - val_loss: 0.5144 - val_accuracy: 0.7396\n",
      "Epoch 459/1500\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4599 - accuracy: 0.7726 - val_loss: 0.5144 - val_accuracy: 0.7396\n",
      "Epoch 460/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4598 - accuracy: 0.7726 - val_loss: 0.5144 - val_accuracy: 0.7396\n",
      "Epoch 461/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4596 - accuracy: 0.7726 - val_loss: 0.5143 - val_accuracy: 0.7396\n",
      "Epoch 462/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4596 - accuracy: 0.7726 - val_loss: 0.5143 - val_accuracy: 0.7396\n",
      "Epoch 463/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4595 - accuracy: 0.7743 - val_loss: 0.5143 - val_accuracy: 0.7396\n",
      "Epoch 464/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4594 - accuracy: 0.7743 - val_loss: 0.5142 - val_accuracy: 0.7396\n",
      "Epoch 465/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4593 - accuracy: 0.7743 - val_loss: 0.5142 - val_accuracy: 0.7396\n",
      "Epoch 466/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4592 - accuracy: 0.7743 - val_loss: 0.5142 - val_accuracy: 0.7396\n",
      "Epoch 467/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4590 - accuracy: 0.7743 - val_loss: 0.5141 - val_accuracy: 0.7396\n",
      "Epoch 468/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4589 - accuracy: 0.7743 - val_loss: 0.5141 - val_accuracy: 0.7396\n",
      "Epoch 469/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4588 - accuracy: 0.7743 - val_loss: 0.5141 - val_accuracy: 0.7396\n",
      "Epoch 470/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4587 - accuracy: 0.7743 - val_loss: 0.5141 - val_accuracy: 0.7396\n",
      "Epoch 471/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4586 - accuracy: 0.7743 - val_loss: 0.5140 - val_accuracy: 0.7396\n",
      "Epoch 472/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4586 - accuracy: 0.7743 - val_loss: 0.5140 - val_accuracy: 0.7396\n",
      "Epoch 473/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4584 - accuracy: 0.7743 - val_loss: 0.5140 - val_accuracy: 0.7396\n",
      "Epoch 474/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4584 - accuracy: 0.7743 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 475/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4582 - accuracy: 0.7743 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 476/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4582 - accuracy: 0.7743 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 477/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4581 - accuracy: 0.7743 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
      "Epoch 478/1500\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4580 - accuracy: 0.7743 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
      "Epoch 479/1500\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4579 - accuracy: 0.7743 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
      "Epoch 480/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4578 - accuracy: 0.7743 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
      "Epoch 481/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4577 - accuracy: 0.7743 - val_loss: 0.5137 - val_accuracy: 0.7396\n",
      "Epoch 482/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4576 - accuracy: 0.7743 - val_loss: 0.5137 - val_accuracy: 0.7396\n",
      "Epoch 483/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4575 - accuracy: 0.7743 - val_loss: 0.5137 - val_accuracy: 0.7396\n",
      "Epoch 484/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4574 - accuracy: 0.7743 - val_loss: 0.5137 - val_accuracy: 0.7396\n",
      "Epoch 485/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4573 - accuracy: 0.7743 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
      "Epoch 486/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4573 - accuracy: 0.7743 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
      "Epoch 487/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4572 - accuracy: 0.7743 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
      "Epoch 488/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4571 - accuracy: 0.7743 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
      "Epoch 489/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4570 - accuracy: 0.7743 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
      "Epoch 490/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4569 - accuracy: 0.7743 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
      "Epoch 491/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4568 - accuracy: 0.7743 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
      "Epoch 492/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4567 - accuracy: 0.7743 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
      "Epoch 493/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4567 - accuracy: 0.7743 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
      "Epoch 494/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4566 - accuracy: 0.7743 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
      "Epoch 495/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4565 - accuracy: 0.7743 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
      "Epoch 496/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4564 - accuracy: 0.7743 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
      "Epoch 497/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4564 - accuracy: 0.7743 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
      "Epoch 498/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4563 - accuracy: 0.7743 - val_loss: 0.5134 - val_accuracy: 0.7396\n",
      "Epoch 499/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4562 - accuracy: 0.7743 - val_loss: 0.5134 - val_accuracy: 0.7396\n",
      "Epoch 500/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4561 - accuracy: 0.7743 - val_loss: 0.5134 - val_accuracy: 0.7396\n",
      "Epoch 501/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4561 - accuracy: 0.7743 - val_loss: 0.5134 - val_accuracy: 0.7396\n",
      "Epoch 502/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4560 - accuracy: 0.7743 - val_loss: 0.5134 - val_accuracy: 0.7396\n",
      "Epoch 503/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4559 - accuracy: 0.7743 - val_loss: 0.5134 - val_accuracy: 0.7396\n",
      "Epoch 504/1500\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4558 - accuracy: 0.7743 - val_loss: 0.5133 - val_accuracy: 0.7396\n",
      "Epoch 505/1500\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4558 - accuracy: 0.7743 - val_loss: 0.5133 - val_accuracy: 0.7396\n",
      "Epoch 506/1500\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4557 - accuracy: 0.7743 - val_loss: 0.5133 - val_accuracy: 0.7396\n",
      "Epoch 507/1500\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4556 - accuracy: 0.7743 - val_loss: 0.5133 - val_accuracy: 0.7396\n",
      "Epoch 508/1500\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4555 - accuracy: 0.7743 - val_loss: 0.5133 - val_accuracy: 0.7396\n",
      "Epoch 509/1500\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4554 - accuracy: 0.7743 - val_loss: 0.5133 - val_accuracy: 0.7396\n",
      "Epoch 510/1500\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4554 - accuracy: 0.7743 - val_loss: 0.5133 - val_accuracy: 0.7396\n",
      "Epoch 511/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4553 - accuracy: 0.7743 - val_loss: 0.5133 - val_accuracy: 0.7396\n",
      "Epoch 512/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4552 - accuracy: 0.7743 - val_loss: 0.5133 - val_accuracy: 0.7396\n",
      "Epoch 513/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4551 - accuracy: 0.7743 - val_loss: 0.5133 - val_accuracy: 0.7344\n",
      "Epoch 514/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4551 - accuracy: 0.7743 - val_loss: 0.5133 - val_accuracy: 0.7344\n",
      "Epoch 515/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4550 - accuracy: 0.7743 - val_loss: 0.5133 - val_accuracy: 0.7344\n",
      "Epoch 516/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4549 - accuracy: 0.7743 - val_loss: 0.5133 - val_accuracy: 0.7344\n",
      "Epoch 517/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4549 - accuracy: 0.7743 - val_loss: 0.5133 - val_accuracy: 0.7344\n",
      "Epoch 518/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4547 - accuracy: 0.7743 - val_loss: 0.5133 - val_accuracy: 0.7344\n",
      "Epoch 519/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4547 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 520/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4546 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 521/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4545 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 522/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4544 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 523/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4544 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 524/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4543 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 525/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4543 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 526/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4541 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 527/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4541 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 528/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4540 - accuracy: 0.7760 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 529/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4539 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 530/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4539 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 531/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4538 - accuracy: 0.7726 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 532/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4537 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 533/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4537 - accuracy: 0.7726 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 534/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4536 - accuracy: 0.7726 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 535/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4535 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 536/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4535 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 537/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4534 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 538/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4533 - accuracy: 0.7760 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 539/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4087 - accuracy: 0.81 - 0s 48us/step - loss: 0.4533 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 540/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4532 - accuracy: 0.7760 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 541/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4531 - accuracy: 0.7760 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 542/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4531 - accuracy: 0.7760 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 543/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4530 - accuracy: 0.7760 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 544/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4530 - accuracy: 0.7760 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 545/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4529 - accuracy: 0.7760 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 546/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4528 - accuracy: 0.7760 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 547/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4527 - accuracy: 0.7760 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 548/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4527 - accuracy: 0.7760 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 549/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4526 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 550/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4526 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 551/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4525 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 552/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4525 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 553/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4524 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 554/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4523 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 555/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4522 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 556/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4522 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 557/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 62us/step - loss: 0.4521 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 558/1500\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4521 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 559/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4520 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 560/1500\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4519 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 561/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4519 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 562/1500\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4518 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 563/1500\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4518 - accuracy: 0.7743 - val_loss: 0.5133 - val_accuracy: 0.7344\n",
      "Epoch 564/1500\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4517 - accuracy: 0.7743 - val_loss: 0.5133 - val_accuracy: 0.7344\n",
      "Epoch 565/1500\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4516 - accuracy: 0.7743 - val_loss: 0.5133 - val_accuracy: 0.7344\n",
      "Epoch 566/1500\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4515 - accuracy: 0.7743 - val_loss: 0.5133 - val_accuracy: 0.7344\n",
      "Epoch 567/1500\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4515 - accuracy: 0.7743 - val_loss: 0.5133 - val_accuracy: 0.7344\n",
      "Epoch 568/1500\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.4514 - accuracy: 0.7743 - val_loss: 0.5133 - val_accuracy: 0.7344\n",
      "Epoch 569/1500\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.4514 - accuracy: 0.7743 - val_loss: 0.5133 - val_accuracy: 0.7344\n",
      "Epoch 570/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4513 - accuracy: 0.7743 - val_loss: 0.5133 - val_accuracy: 0.7344\n",
      "Epoch 571/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4512 - accuracy: 0.7743 - val_loss: 0.5133 - val_accuracy: 0.7344\n",
      "Epoch 572/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4511 - accuracy: 0.7743 - val_loss: 0.5133 - val_accuracy: 0.7344\n",
      "Epoch 573/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4511 - accuracy: 0.7743 - val_loss: 0.5133 - val_accuracy: 0.7344\n",
      "Epoch 574/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4510 - accuracy: 0.7743 - val_loss: 0.5133 - val_accuracy: 0.7344\n",
      "Epoch 575/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4509 - accuracy: 0.7726 - val_loss: 0.5133 - val_accuracy: 0.7344\n",
      "Epoch 576/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4509 - accuracy: 0.7726 - val_loss: 0.5133 - val_accuracy: 0.7344\n",
      "Epoch 577/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4508 - accuracy: 0.7726 - val_loss: 0.5133 - val_accuracy: 0.7344\n",
      "Epoch 578/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4508 - accuracy: 0.7743 - val_loss: 0.5133 - val_accuracy: 0.7344\n",
      "Epoch 579/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4507 - accuracy: 0.7726 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 580/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4506 - accuracy: 0.7708 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 581/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4506 - accuracy: 0.7726 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 582/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4504 - accuracy: 0.7726 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 583/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4504 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 584/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4504 - accuracy: 0.7726 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 585/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4503 - accuracy: 0.7726 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 586/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4502 - accuracy: 0.7726 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 587/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4502 - accuracy: 0.7726 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 588/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4501 - accuracy: 0.7726 - val_loss: 0.5132 - val_accuracy: 0.7396\n",
      "Epoch 589/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4500 - accuracy: 0.7726 - val_loss: 0.5132 - val_accuracy: 0.7396\n",
      "Epoch 590/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4500 - accuracy: 0.7726 - val_loss: 0.5132 - val_accuracy: 0.7396\n",
      "Epoch 591/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4499 - accuracy: 0.7726 - val_loss: 0.5132 - val_accuracy: 0.7396\n",
      "Epoch 592/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4499 - accuracy: 0.7726 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
      "Epoch 593/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4498 - accuracy: 0.7726 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
      "Epoch 594/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4498 - accuracy: 0.7726 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 595/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4497 - accuracy: 0.7726 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 596/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4496 - accuracy: 0.7726 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 597/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4496 - accuracy: 0.7726 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 598/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4495 - accuracy: 0.7726 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 599/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4494 - accuracy: 0.7726 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 600/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4494 - accuracy: 0.7726 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 601/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4493 - accuracy: 0.7726 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 602/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4492 - accuracy: 0.7726 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 603/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4492 - accuracy: 0.7726 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 604/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4491 - accuracy: 0.7726 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 605/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4491 - accuracy: 0.7726 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 606/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4491 - accuracy: 0.7708 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 607/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4490 - accuracy: 0.7726 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 608/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4489 - accuracy: 0.7726 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 609/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4489 - accuracy: 0.7708 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 610/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4488 - accuracy: 0.7726 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
      "Epoch 611/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4487 - accuracy: 0.7708 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
      "Epoch 612/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4487 - accuracy: 0.7708 - val_loss: 0.5132 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 613/1500\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4486 - accuracy: 0.7708 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
      "Epoch 614/1500\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4486 - accuracy: 0.7708 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
      "Epoch 615/1500\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4485 - accuracy: 0.7708 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
      "Epoch 616/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4484 - accuracy: 0.7708 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
      "Epoch 617/1500\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4484 - accuracy: 0.7708 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
      "Epoch 618/1500\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4483 - accuracy: 0.7708 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
      "Epoch 619/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4483 - accuracy: 0.7708 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
      "Epoch 620/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4482 - accuracy: 0.7708 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
      "Epoch 621/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4482 - accuracy: 0.7708 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 622/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4481 - accuracy: 0.7708 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 623/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4481 - accuracy: 0.7708 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 624/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4480 - accuracy: 0.7708 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 625/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4479 - accuracy: 0.7708 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 626/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4479 - accuracy: 0.7708 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 627/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4478 - accuracy: 0.7708 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 628/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4477 - accuracy: 0.7708 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 629/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4477 - accuracy: 0.7708 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 630/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4477 - accuracy: 0.7708 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 631/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4476 - accuracy: 0.7708 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 632/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4475 - accuracy: 0.7708 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 633/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4475 - accuracy: 0.7708 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 634/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4474 - accuracy: 0.7708 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 635/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4473 - accuracy: 0.7708 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 636/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4473 - accuracy: 0.7708 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 637/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4472 - accuracy: 0.7708 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 638/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4472 - accuracy: 0.7708 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 639/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4471 - accuracy: 0.7708 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 640/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4471 - accuracy: 0.7726 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 641/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4470 - accuracy: 0.7726 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 642/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4469 - accuracy: 0.7726 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 643/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4469 - accuracy: 0.7726 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 644/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4468 - accuracy: 0.7726 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 645/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3606 - accuracy: 0.84 - 0s 42us/step - loss: 0.4467 - accuracy: 0.7726 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 646/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4467 - accuracy: 0.7726 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 647/1500\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4466 - accuracy: 0.7726 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 648/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4466 - accuracy: 0.7726 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 649/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4465 - accuracy: 0.7726 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 650/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4464 - accuracy: 0.7726 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 651/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4464 - accuracy: 0.7726 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 652/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4463 - accuracy: 0.7726 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 653/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4463 - accuracy: 0.7726 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 654/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4462 - accuracy: 0.7726 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 655/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4462 - accuracy: 0.7726 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 656/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4461 - accuracy: 0.7726 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 657/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4460 - accuracy: 0.7726 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 658/1500\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4460 - accuracy: 0.7726 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 659/1500\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4459 - accuracy: 0.7726 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 660/1500\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4459 - accuracy: 0.7726 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 661/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4458 - accuracy: 0.7726 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 662/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4458 - accuracy: 0.7726 - val_loss: 0.5129 - val_accuracy: 0.7448\n",
      "Epoch 663/1500\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4458 - accuracy: 0.7726 - val_loss: 0.5129 - val_accuracy: 0.7448\n",
      "Epoch 664/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4457 - accuracy: 0.7726 - val_loss: 0.5129 - val_accuracy: 0.7448\n",
      "Epoch 665/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4457 - accuracy: 0.7726 - val_loss: 0.5129 - val_accuracy: 0.7448\n",
      "Epoch 666/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4456 - accuracy: 0.7726 - val_loss: 0.5129 - val_accuracy: 0.7448\n",
      "Epoch 667/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4455 - accuracy: 0.7726 - val_loss: 0.5129 - val_accuracy: 0.7448\n",
      "Epoch 668/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4455 - accuracy: 0.7726 - val_loss: 0.5129 - val_accuracy: 0.7448\n",
      "Epoch 669/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4455 - accuracy: 0.7726 - val_loss: 0.5129 - val_accuracy: 0.7448\n",
      "Epoch 670/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4454 - accuracy: 0.7726 - val_loss: 0.5129 - val_accuracy: 0.7448\n",
      "Epoch 671/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4453 - accuracy: 0.7726 - val_loss: 0.5129 - val_accuracy: 0.7448\n",
      "Epoch 672/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4453 - accuracy: 0.7726 - val_loss: 0.5129 - val_accuracy: 0.7448\n",
      "Epoch 673/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4452 - accuracy: 0.7726 - val_loss: 0.5129 - val_accuracy: 0.7448\n",
      "Epoch 674/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4452 - accuracy: 0.7726 - val_loss: 0.5129 - val_accuracy: 0.7448\n",
      "Epoch 675/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4452 - accuracy: 0.7726 - val_loss: 0.5128 - val_accuracy: 0.7448\n",
      "Epoch 676/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4451 - accuracy: 0.7726 - val_loss: 0.5128 - val_accuracy: 0.7448\n",
      "Epoch 677/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4450 - accuracy: 0.7726 - val_loss: 0.5128 - val_accuracy: 0.7448\n",
      "Epoch 678/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4450 - accuracy: 0.7726 - val_loss: 0.5128 - val_accuracy: 0.7448\n",
      "Epoch 679/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4450 - accuracy: 0.7743 - val_loss: 0.5128 - val_accuracy: 0.7448\n",
      "Epoch 680/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4449 - accuracy: 0.7726 - val_loss: 0.5128 - val_accuracy: 0.7448\n",
      "Epoch 681/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4449 - accuracy: 0.7743 - val_loss: 0.5128 - val_accuracy: 0.7448\n",
      "Epoch 682/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4448 - accuracy: 0.7726 - val_loss: 0.5128 - val_accuracy: 0.7448\n",
      "Epoch 683/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4448 - accuracy: 0.7743 - val_loss: 0.5128 - val_accuracy: 0.7448\n",
      "Epoch 684/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4447 - accuracy: 0.7743 - val_loss: 0.5128 - val_accuracy: 0.7448\n",
      "Epoch 685/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4447 - accuracy: 0.7743 - val_loss: 0.5128 - val_accuracy: 0.7448\n",
      "Epoch 686/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4447 - accuracy: 0.7726 - val_loss: 0.5128 - val_accuracy: 0.7448\n",
      "Epoch 687/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4446 - accuracy: 0.7743 - val_loss: 0.5127 - val_accuracy: 0.7448\n",
      "Epoch 688/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4445 - accuracy: 0.7743 - val_loss: 0.5127 - val_accuracy: 0.7448\n",
      "Epoch 689/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4445 - accuracy: 0.7743 - val_loss: 0.5127 - val_accuracy: 0.7448\n",
      "Epoch 690/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4445 - accuracy: 0.7743 - val_loss: 0.5127 - val_accuracy: 0.7448\n",
      "Epoch 691/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4444 - accuracy: 0.7743 - val_loss: 0.5127 - val_accuracy: 0.7448\n",
      "Epoch 692/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4444 - accuracy: 0.7743 - val_loss: 0.5127 - val_accuracy: 0.7448\n",
      "Epoch 693/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4443 - accuracy: 0.7743 - val_loss: 0.5127 - val_accuracy: 0.7448\n",
      "Epoch 694/1500\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4443 - accuracy: 0.7743 - val_loss: 0.5127 - val_accuracy: 0.7448\n",
      "Epoch 695/1500\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4442 - accuracy: 0.7743 - val_loss: 0.5126 - val_accuracy: 0.7448\n",
      "Epoch 696/1500\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4442 - accuracy: 0.7743 - val_loss: 0.5126 - val_accuracy: 0.7448\n",
      "Epoch 697/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4441 - accuracy: 0.7743 - val_loss: 0.5126 - val_accuracy: 0.7448\n",
      "Epoch 698/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4441 - accuracy: 0.7743 - val_loss: 0.5126 - val_accuracy: 0.7448\n",
      "Epoch 699/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4441 - accuracy: 0.7743 - val_loss: 0.5126 - val_accuracy: 0.7448\n",
      "Epoch 700/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4440 - accuracy: 0.7743 - val_loss: 0.5126 - val_accuracy: 0.7448\n",
      "Epoch 701/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4440 - accuracy: 0.7760 - val_loss: 0.5126 - val_accuracy: 0.7448\n",
      "Epoch 702/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4439 - accuracy: 0.7760 - val_loss: 0.5125 - val_accuracy: 0.7448\n",
      "Epoch 703/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4439 - accuracy: 0.7760 - val_loss: 0.5125 - val_accuracy: 0.7448\n",
      "Epoch 704/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4438 - accuracy: 0.7760 - val_loss: 0.5125 - val_accuracy: 0.7448\n",
      "Epoch 705/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4438 - accuracy: 0.7760 - val_loss: 0.5125 - val_accuracy: 0.7448\n",
      "Epoch 706/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4437 - accuracy: 0.7760 - val_loss: 0.5125 - val_accuracy: 0.7448\n",
      "Epoch 707/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4437 - accuracy: 0.7760 - val_loss: 0.5125 - val_accuracy: 0.7448\n",
      "Epoch 708/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4437 - accuracy: 0.7760 - val_loss: 0.5125 - val_accuracy: 0.7448\n",
      "Epoch 709/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4436 - accuracy: 0.7760 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 710/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4435 - accuracy: 0.7760 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 711/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4435 - accuracy: 0.7760 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 712/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4435 - accuracy: 0.7760 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 713/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4434 - accuracy: 0.7760 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 714/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4434 - accuracy: 0.7760 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 715/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4433 - accuracy: 0.7760 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 716/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4433 - accuracy: 0.7760 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 717/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4433 - accuracy: 0.7760 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 718/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4432 - accuracy: 0.7760 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 719/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4431 - accuracy: 0.7760 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 720/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4431 - accuracy: 0.7778 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 721/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4431 - accuracy: 0.7743 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 722/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4430 - accuracy: 0.7760 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 723/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4430 - accuracy: 0.7743 - val_loss: 0.5123 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 724/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4430 - accuracy: 0.7760 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 725/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4429 - accuracy: 0.7743 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 726/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4429 - accuracy: 0.7743 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 727/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4429 - accuracy: 0.7726 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 728/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4428 - accuracy: 0.7760 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 729/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4427 - accuracy: 0.7743 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 730/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4427 - accuracy: 0.7760 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 731/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4427 - accuracy: 0.7760 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 732/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4426 - accuracy: 0.7743 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 733/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4426 - accuracy: 0.7726 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 734/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4426 - accuracy: 0.7743 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 735/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4425 - accuracy: 0.7743 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 736/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4425 - accuracy: 0.7743 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 737/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4424 - accuracy: 0.7726 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 738/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4424 - accuracy: 0.7743 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 739/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4424 - accuracy: 0.7743 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 740/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4423 - accuracy: 0.7743 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 741/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4422 - accuracy: 0.7743 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 742/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4422 - accuracy: 0.7743 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 743/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4422 - accuracy: 0.7743 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 744/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4421 - accuracy: 0.7743 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 745/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4421 - accuracy: 0.7743 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 746/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4421 - accuracy: 0.7743 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 747/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4420 - accuracy: 0.7743 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 748/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4420 - accuracy: 0.7743 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 749/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4419 - accuracy: 0.7743 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 750/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4419 - accuracy: 0.7743 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 751/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4419 - accuracy: 0.7743 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 752/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4418 - accuracy: 0.7743 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 753/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4418 - accuracy: 0.7726 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 754/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4417 - accuracy: 0.7743 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 755/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4417 - accuracy: 0.7726 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 756/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4417 - accuracy: 0.7743 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 757/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4416 - accuracy: 0.7726 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 758/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4416 - accuracy: 0.7726 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 759/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4415 - accuracy: 0.7726 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 760/1500\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4415 - accuracy: 0.7726 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 761/1500\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4415 - accuracy: 0.7726 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 762/1500\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.4414 - accuracy: 0.7726 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 763/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4414 - accuracy: 0.7726 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 764/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4413 - accuracy: 0.7743 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 765/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4413 - accuracy: 0.7726 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 766/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4413 - accuracy: 0.7726 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 767/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4412 - accuracy: 0.7743 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 768/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4412 - accuracy: 0.7726 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 769/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4411 - accuracy: 0.7743 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 770/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4411 - accuracy: 0.7743 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 771/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4411 - accuracy: 0.7726 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 772/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4410 - accuracy: 0.7743 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 773/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4410 - accuracy: 0.7743 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 774/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4409 - accuracy: 0.7743 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 775/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4409 - accuracy: 0.7743 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 776/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4409 - accuracy: 0.7726 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 777/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4408 - accuracy: 0.7760 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 778/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4408 - accuracy: 0.7760 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 779/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4407 - accuracy: 0.7760 - val_loss: 0.5124 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 780/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4407 - accuracy: 0.7760 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 781/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4406 - accuracy: 0.7760 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 782/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4406 - accuracy: 0.7760 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 783/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4406 - accuracy: 0.7760 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 784/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4405 - accuracy: 0.7760 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 785/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4405 - accuracy: 0.7760 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 786/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4404 - accuracy: 0.7760 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 787/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4404 - accuracy: 0.7760 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 788/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4404 - accuracy: 0.7760 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 789/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4403 - accuracy: 0.7760 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 790/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4403 - accuracy: 0.7760 - val_loss: 0.5125 - val_accuracy: 0.7448\n",
      "Epoch 791/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4402 - accuracy: 0.7778 - val_loss: 0.5125 - val_accuracy: 0.7448\n",
      "Epoch 792/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4402 - accuracy: 0.7778 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 793/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4402 - accuracy: 0.7760 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 794/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4401 - accuracy: 0.7778 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 795/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4401 - accuracy: 0.7778 - val_loss: 0.5124 - val_accuracy: 0.7500\n",
      "Epoch 796/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4400 - accuracy: 0.7778 - val_loss: 0.5124 - val_accuracy: 0.7500\n",
      "Epoch 797/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4400 - accuracy: 0.7778 - val_loss: 0.5124 - val_accuracy: 0.7500\n",
      "Epoch 798/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4400 - accuracy: 0.7778 - val_loss: 0.5124 - val_accuracy: 0.7500\n",
      "Epoch 799/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4399 - accuracy: 0.7778 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
      "Epoch 800/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4399 - accuracy: 0.7778 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
      "Epoch 801/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4398 - accuracy: 0.7778 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
      "Epoch 802/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4398 - accuracy: 0.7778 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
      "Epoch 803/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4397 - accuracy: 0.7778 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
      "Epoch 804/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4397 - accuracy: 0.7778 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
      "Epoch 805/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4397 - accuracy: 0.7778 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
      "Epoch 806/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4396 - accuracy: 0.7778 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
      "Epoch 807/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4396 - accuracy: 0.7778 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
      "Epoch 808/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4396 - accuracy: 0.7778 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
      "Epoch 809/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4395 - accuracy: 0.7778 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
      "Epoch 810/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4395 - accuracy: 0.7778 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 811/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4394 - accuracy: 0.7778 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 812/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4394 - accuracy: 0.7778 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 813/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4393 - accuracy: 0.7778 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 814/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4393 - accuracy: 0.7778 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 815/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4393 - accuracy: 0.7778 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 816/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4392 - accuracy: 0.7778 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 817/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4392 - accuracy: 0.7778 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
      "Epoch 818/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4391 - accuracy: 0.7778 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
      "Epoch 819/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4391 - accuracy: 0.7778 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
      "Epoch 820/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4391 - accuracy: 0.7778 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
      "Epoch 821/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4390 - accuracy: 0.7778 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
      "Epoch 822/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4389 - accuracy: 0.7778 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
      "Epoch 823/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4389 - accuracy: 0.7778 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
      "Epoch 824/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4389 - accuracy: 0.7778 - val_loss: 0.5129 - val_accuracy: 0.7500\n",
      "Epoch 825/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4388 - accuracy: 0.7778 - val_loss: 0.5129 - val_accuracy: 0.7500\n",
      "Epoch 826/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4388 - accuracy: 0.7778 - val_loss: 0.5129 - val_accuracy: 0.7500\n",
      "Epoch 827/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4387 - accuracy: 0.7778 - val_loss: 0.5129 - val_accuracy: 0.7500\n",
      "Epoch 828/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4387 - accuracy: 0.7778 - val_loss: 0.5129 - val_accuracy: 0.7500\n",
      "Epoch 829/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4386 - accuracy: 0.7778 - val_loss: 0.5129 - val_accuracy: 0.7448\n",
      "Epoch 830/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4386 - accuracy: 0.7778 - val_loss: 0.5129 - val_accuracy: 0.7448\n",
      "Epoch 831/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4386 - accuracy: 0.7778 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 832/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4385 - accuracy: 0.7778 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 833/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4385 - accuracy: 0.7778 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 834/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4384 - accuracy: 0.7778 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 835/1500\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4384 - accuracy: 0.7778 - val_loss: 0.5131 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 836/1500\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4384 - accuracy: 0.7778 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 837/1500\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4383 - accuracy: 0.7778 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 838/1500\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4383 - accuracy: 0.7778 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 839/1500\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4382 - accuracy: 0.7760 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
      "Epoch 840/1500\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4382 - accuracy: 0.7778 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
      "Epoch 841/1500\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.4382 - accuracy: 0.7778 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
      "Epoch 842/1500\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4381 - accuracy: 0.7778 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
      "Epoch 843/1500\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4380 - accuracy: 0.7760 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
      "Epoch 844/1500\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4380 - accuracy: 0.7760 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
      "Epoch 845/1500\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4380 - accuracy: 0.7760 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
      "Epoch 846/1500\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4379 - accuracy: 0.7760 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
      "Epoch 847/1500\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4379 - accuracy: 0.7778 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
      "Epoch 848/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4379 - accuracy: 0.7760 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
      "Epoch 849/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4378 - accuracy: 0.7760 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
      "Epoch 850/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4378 - accuracy: 0.7760 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
      "Epoch 851/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4377 - accuracy: 0.7760 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
      "Epoch 852/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4377 - accuracy: 0.7760 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
      "Epoch 853/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4377 - accuracy: 0.7760 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
      "Epoch 854/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4377 - accuracy: 0.7760 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
      "Epoch 855/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4376 - accuracy: 0.7760 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
      "Epoch 856/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4375 - accuracy: 0.7760 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
      "Epoch 857/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4375 - accuracy: 0.7760 - val_loss: 0.5136 - val_accuracy: 0.7448\n",
      "Epoch 858/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4375 - accuracy: 0.7760 - val_loss: 0.5136 - val_accuracy: 0.7448\n",
      "Epoch 859/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4375 - accuracy: 0.7760 - val_loss: 0.5136 - val_accuracy: 0.7448\n",
      "Epoch 860/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4374 - accuracy: 0.7760 - val_loss: 0.5136 - val_accuracy: 0.7448\n",
      "Epoch 861/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4373 - accuracy: 0.7760 - val_loss: 0.5137 - val_accuracy: 0.7448\n",
      "Epoch 862/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4373 - accuracy: 0.7760 - val_loss: 0.5137 - val_accuracy: 0.7448\n",
      "Epoch 863/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4373 - accuracy: 0.7760 - val_loss: 0.5137 - val_accuracy: 0.7448\n",
      "Epoch 864/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4372 - accuracy: 0.7760 - val_loss: 0.5138 - val_accuracy: 0.7448\n",
      "Epoch 865/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4372 - accuracy: 0.7760 - val_loss: 0.5138 - val_accuracy: 0.7448\n",
      "Epoch 866/1500\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4372 - accuracy: 0.7760 - val_loss: 0.5138 - val_accuracy: 0.7448\n",
      "Epoch 867/1500\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4371 - accuracy: 0.7760 - val_loss: 0.5138 - val_accuracy: 0.7448\n",
      "Epoch 868/1500\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4371 - accuracy: 0.7760 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 869/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4370 - accuracy: 0.7760 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 870/1500\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4370 - accuracy: 0.7760 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 871/1500\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4370 - accuracy: 0.7760 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 872/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4369 - accuracy: 0.7760 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 873/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4368 - accuracy: 0.7778 - val_loss: 0.5141 - val_accuracy: 0.7448\n",
      "Epoch 874/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4368 - accuracy: 0.7760 - val_loss: 0.5141 - val_accuracy: 0.7448\n",
      "Epoch 875/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4368 - accuracy: 0.7760 - val_loss: 0.5142 - val_accuracy: 0.7448\n",
      "Epoch 876/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4367 - accuracy: 0.7760 - val_loss: 0.5142 - val_accuracy: 0.7448\n",
      "Epoch 877/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4367 - accuracy: 0.7778 - val_loss: 0.5143 - val_accuracy: 0.7448\n",
      "Epoch 878/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4366 - accuracy: 0.7760 - val_loss: 0.5143 - val_accuracy: 0.7448\n",
      "Epoch 879/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4366 - accuracy: 0.7778 - val_loss: 0.5144 - val_accuracy: 0.7448\n",
      "Epoch 880/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4365 - accuracy: 0.7778 - val_loss: 0.5144 - val_accuracy: 0.7448\n",
      "Epoch 881/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4365 - accuracy: 0.7760 - val_loss: 0.5145 - val_accuracy: 0.7448\n",
      "Epoch 882/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4364 - accuracy: 0.7778 - val_loss: 0.5145 - val_accuracy: 0.7448\n",
      "Epoch 883/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4364 - accuracy: 0.7778 - val_loss: 0.5146 - val_accuracy: 0.7448\n",
      "Epoch 884/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4363 - accuracy: 0.7760 - val_loss: 0.5146 - val_accuracy: 0.7448\n",
      "Epoch 885/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4363 - accuracy: 0.7760 - val_loss: 0.5147 - val_accuracy: 0.7448\n",
      "Epoch 886/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4362 - accuracy: 0.7778 - val_loss: 0.5147 - val_accuracy: 0.7448\n",
      "Epoch 887/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4362 - accuracy: 0.7760 - val_loss: 0.5148 - val_accuracy: 0.7448\n",
      "Epoch 888/1500\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.4361 - accuracy: 0.7760 - val_loss: 0.5148 - val_accuracy: 0.7448\n",
      "Epoch 889/1500\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4361 - accuracy: 0.7778 - val_loss: 0.5148 - val_accuracy: 0.7448\n",
      "Epoch 890/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4360 - accuracy: 0.7760 - val_loss: 0.5148 - val_accuracy: 0.7448\n",
      "Epoch 891/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4360 - accuracy: 0.7760 - val_loss: 0.5149 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 892/1500\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4360 - accuracy: 0.7760 - val_loss: 0.5149 - val_accuracy: 0.7448\n",
      "Epoch 893/1500\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4359 - accuracy: 0.7760 - val_loss: 0.5149 - val_accuracy: 0.7448\n",
      "Epoch 894/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4358 - accuracy: 0.7760 - val_loss: 0.5150 - val_accuracy: 0.7448\n",
      "Epoch 895/1500\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4358 - accuracy: 0.7760 - val_loss: 0.5150 - val_accuracy: 0.7448\n",
      "Epoch 896/1500\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4358 - accuracy: 0.7760 - val_loss: 0.5150 - val_accuracy: 0.7448\n",
      "Epoch 897/1500\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4357 - accuracy: 0.7778 - val_loss: 0.5151 - val_accuracy: 0.7448\n",
      "Epoch 898/1500\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4357 - accuracy: 0.7760 - val_loss: 0.5151 - val_accuracy: 0.7448\n",
      "Epoch 899/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4357 - accuracy: 0.7778 - val_loss: 0.5151 - val_accuracy: 0.7448\n",
      "Epoch 900/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4356 - accuracy: 0.7760 - val_loss: 0.5152 - val_accuracy: 0.7448\n",
      "Epoch 901/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4355 - accuracy: 0.7743 - val_loss: 0.5152 - val_accuracy: 0.7448\n",
      "Epoch 902/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4355 - accuracy: 0.7760 - val_loss: 0.5152 - val_accuracy: 0.7448\n",
      "Epoch 903/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4355 - accuracy: 0.7760 - val_loss: 0.5152 - val_accuracy: 0.7448\n",
      "Epoch 904/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4354 - accuracy: 0.7743 - val_loss: 0.5153 - val_accuracy: 0.7448\n",
      "Epoch 905/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4354 - accuracy: 0.7760 - val_loss: 0.5153 - val_accuracy: 0.7448\n",
      "Epoch 906/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4353 - accuracy: 0.7760 - val_loss: 0.5153 - val_accuracy: 0.7448\n",
      "Epoch 907/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4353 - accuracy: 0.7760 - val_loss: 0.5153 - val_accuracy: 0.7448\n",
      "Epoch 908/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4352 - accuracy: 0.7743 - val_loss: 0.5154 - val_accuracy: 0.7448\n",
      "Epoch 909/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4352 - accuracy: 0.7743 - val_loss: 0.5154 - val_accuracy: 0.7448\n",
      "Epoch 910/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4352 - accuracy: 0.7760 - val_loss: 0.5154 - val_accuracy: 0.7448\n",
      "Epoch 911/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4351 - accuracy: 0.7743 - val_loss: 0.5154 - val_accuracy: 0.7448\n",
      "Epoch 912/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4351 - accuracy: 0.7760 - val_loss: 0.5155 - val_accuracy: 0.7448\n",
      "Epoch 913/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4351 - accuracy: 0.7760 - val_loss: 0.5155 - val_accuracy: 0.7448\n",
      "Epoch 914/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4351 - accuracy: 0.7743 - val_loss: 0.5155 - val_accuracy: 0.7448\n",
      "Epoch 915/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4350 - accuracy: 0.7760 - val_loss: 0.5155 - val_accuracy: 0.7448\n",
      "Epoch 916/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4350 - accuracy: 0.7760 - val_loss: 0.5156 - val_accuracy: 0.7448\n",
      "Epoch 917/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4349 - accuracy: 0.7760 - val_loss: 0.5156 - val_accuracy: 0.7448\n",
      "Epoch 918/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4349 - accuracy: 0.7743 - val_loss: 0.5156 - val_accuracy: 0.7448\n",
      "Epoch 919/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4348 - accuracy: 0.7760 - val_loss: 0.5157 - val_accuracy: 0.7448\n",
      "Epoch 920/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4348 - accuracy: 0.7760 - val_loss: 0.5157 - val_accuracy: 0.7448\n",
      "Epoch 921/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4347 - accuracy: 0.7760 - val_loss: 0.5157 - val_accuracy: 0.7448\n",
      "Epoch 922/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4347 - accuracy: 0.7743 - val_loss: 0.5157 - val_accuracy: 0.7448\n",
      "Epoch 923/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4347 - accuracy: 0.7743 - val_loss: 0.5157 - val_accuracy: 0.7448\n",
      "Epoch 924/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4346 - accuracy: 0.7760 - val_loss: 0.5158 - val_accuracy: 0.7448\n",
      "Epoch 925/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4346 - accuracy: 0.7743 - val_loss: 0.5158 - val_accuracy: 0.7448\n",
      "Epoch 926/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4345 - accuracy: 0.7760 - val_loss: 0.5158 - val_accuracy: 0.7448\n",
      "Epoch 927/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4345 - accuracy: 0.7760 - val_loss: 0.5158 - val_accuracy: 0.7448\n",
      "Epoch 928/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4345 - accuracy: 0.7778 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 929/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4344 - accuracy: 0.7743 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 930/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4344 - accuracy: 0.7778 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 931/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4343 - accuracy: 0.7778 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 932/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4343 - accuracy: 0.7778 - val_loss: 0.5160 - val_accuracy: 0.7448\n",
      "Epoch 933/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4343 - accuracy: 0.7778 - val_loss: 0.5160 - val_accuracy: 0.7448\n",
      "Epoch 934/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4342 - accuracy: 0.7760 - val_loss: 0.5160 - val_accuracy: 0.7448\n",
      "Epoch 935/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4342 - accuracy: 0.7778 - val_loss: 0.5160 - val_accuracy: 0.7448\n",
      "Epoch 936/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4341 - accuracy: 0.7795 - val_loss: 0.5161 - val_accuracy: 0.7448\n",
      "Epoch 937/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4341 - accuracy: 0.7795 - val_loss: 0.5161 - val_accuracy: 0.7448\n",
      "Epoch 938/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4340 - accuracy: 0.7795 - val_loss: 0.5161 - val_accuracy: 0.7448\n",
      "Epoch 939/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4340 - accuracy: 0.7795 - val_loss: 0.5161 - val_accuracy: 0.7448\n",
      "Epoch 940/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4340 - accuracy: 0.7795 - val_loss: 0.5161 - val_accuracy: 0.7448\n",
      "Epoch 941/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4339 - accuracy: 0.7795 - val_loss: 0.5162 - val_accuracy: 0.7448\n",
      "Epoch 942/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4339 - accuracy: 0.7795 - val_loss: 0.5162 - val_accuracy: 0.7448\n",
      "Epoch 943/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4338 - accuracy: 0.7795 - val_loss: 0.5162 - val_accuracy: 0.7448\n",
      "Epoch 944/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4338 - accuracy: 0.7795 - val_loss: 0.5162 - val_accuracy: 0.7396\n",
      "Epoch 945/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4338 - accuracy: 0.7795 - val_loss: 0.5162 - val_accuracy: 0.7396\n",
      "Epoch 946/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4337 - accuracy: 0.7795 - val_loss: 0.5162 - val_accuracy: 0.7396\n",
      "Epoch 947/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4337 - accuracy: 0.7795 - val_loss: 0.5163 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 948/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4336 - accuracy: 0.7778 - val_loss: 0.5163 - val_accuracy: 0.7396\n",
      "Epoch 949/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4336 - accuracy: 0.7795 - val_loss: 0.5163 - val_accuracy: 0.7396\n",
      "Epoch 950/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4336 - accuracy: 0.7778 - val_loss: 0.5163 - val_accuracy: 0.7396\n",
      "Epoch 951/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4335 - accuracy: 0.7795 - val_loss: 0.5163 - val_accuracy: 0.7396\n",
      "Epoch 952/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4335 - accuracy: 0.7778 - val_loss: 0.5164 - val_accuracy: 0.7396\n",
      "Epoch 953/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4335 - accuracy: 0.7778 - val_loss: 0.5164 - val_accuracy: 0.7396\n",
      "Epoch 954/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4334 - accuracy: 0.7778 - val_loss: 0.5164 - val_accuracy: 0.7396\n",
      "Epoch 955/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4334 - accuracy: 0.7795 - val_loss: 0.5164 - val_accuracy: 0.7396\n",
      "Epoch 956/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4334 - accuracy: 0.7778 - val_loss: 0.5165 - val_accuracy: 0.7396\n",
      "Epoch 957/1500\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4333 - accuracy: 0.7795 - val_loss: 0.5165 - val_accuracy: 0.7396\n",
      "Epoch 958/1500\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4332 - accuracy: 0.7795 - val_loss: 0.5165 - val_accuracy: 0.7396\n",
      "Epoch 959/1500\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4332 - accuracy: 0.7795 - val_loss: 0.5166 - val_accuracy: 0.7396\n",
      "Epoch 960/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4331 - accuracy: 0.7795 - val_loss: 0.5166 - val_accuracy: 0.7396\n",
      "Epoch 961/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4331 - accuracy: 0.7795 - val_loss: 0.5166 - val_accuracy: 0.7396\n",
      "Epoch 962/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4331 - accuracy: 0.7795 - val_loss: 0.5166 - val_accuracy: 0.7396\n",
      "Epoch 963/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4330 - accuracy: 0.7795 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 964/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4330 - accuracy: 0.7795 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 965/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4329 - accuracy: 0.7795 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 966/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4329 - accuracy: 0.7795 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 967/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4329 - accuracy: 0.7795 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 968/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4328 - accuracy: 0.7795 - val_loss: 0.5168 - val_accuracy: 0.7396\n",
      "Epoch 969/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4328 - accuracy: 0.7795 - val_loss: 0.5168 - val_accuracy: 0.7396\n",
      "Epoch 970/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4328 - accuracy: 0.7795 - val_loss: 0.5168 - val_accuracy: 0.7396\n",
      "Epoch 971/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4327 - accuracy: 0.7795 - val_loss: 0.5168 - val_accuracy: 0.7396\n",
      "Epoch 972/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4327 - accuracy: 0.7795 - val_loss: 0.5168 - val_accuracy: 0.7396\n",
      "Epoch 973/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4326 - accuracy: 0.7795 - val_loss: 0.5168 - val_accuracy: 0.7396\n",
      "Epoch 974/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4326 - accuracy: 0.7795 - val_loss: 0.5169 - val_accuracy: 0.7396\n",
      "Epoch 975/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4326 - accuracy: 0.7795 - val_loss: 0.5169 - val_accuracy: 0.7396\n",
      "Epoch 976/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4325 - accuracy: 0.7795 - val_loss: 0.5169 - val_accuracy: 0.7396\n",
      "Epoch 977/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4325 - accuracy: 0.7795 - val_loss: 0.5169 - val_accuracy: 0.7396\n",
      "Epoch 978/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4325 - accuracy: 0.7795 - val_loss: 0.5170 - val_accuracy: 0.7396\n",
      "Epoch 979/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4324 - accuracy: 0.7795 - val_loss: 0.5170 - val_accuracy: 0.7396\n",
      "Epoch 980/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4324 - accuracy: 0.7795 - val_loss: 0.5170 - val_accuracy: 0.7396\n",
      "Epoch 981/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4324 - accuracy: 0.7795 - val_loss: 0.5170 - val_accuracy: 0.7396\n",
      "Epoch 982/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4323 - accuracy: 0.7795 - val_loss: 0.5170 - val_accuracy: 0.7396\n",
      "Epoch 983/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4323 - accuracy: 0.7795 - val_loss: 0.5171 - val_accuracy: 0.7396\n",
      "Epoch 984/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4323 - accuracy: 0.7795 - val_loss: 0.5171 - val_accuracy: 0.7396\n",
      "Epoch 985/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4322 - accuracy: 0.7795 - val_loss: 0.5171 - val_accuracy: 0.7396\n",
      "Epoch 986/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4322 - accuracy: 0.7795 - val_loss: 0.5171 - val_accuracy: 0.7396\n",
      "Epoch 987/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4321 - accuracy: 0.7795 - val_loss: 0.5171 - val_accuracy: 0.7396\n",
      "Epoch 988/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4320 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7396\n",
      "Epoch 989/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4320 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7396\n",
      "Epoch 990/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4320 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7396\n",
      "Epoch 991/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4320 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7396\n",
      "Epoch 992/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4319 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7396\n",
      "Epoch 993/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4318 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7396\n",
      "Epoch 994/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4318 - accuracy: 0.7795 - val_loss: 0.5173 - val_accuracy: 0.7396\n",
      "Epoch 995/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4318 - accuracy: 0.7795 - val_loss: 0.5173 - val_accuracy: 0.7396\n",
      "Epoch 996/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4317 - accuracy: 0.7795 - val_loss: 0.5173 - val_accuracy: 0.7396\n",
      "Epoch 997/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4317 - accuracy: 0.7795 - val_loss: 0.5173 - val_accuracy: 0.7396\n",
      "Epoch 998/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4317 - accuracy: 0.7795 - val_loss: 0.5173 - val_accuracy: 0.7396\n",
      "Epoch 999/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4317 - accuracy: 0.7795 - val_loss: 0.5173 - val_accuracy: 0.7396\n",
      "Epoch 1000/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4316 - accuracy: 0.7795 - val_loss: 0.5173 - val_accuracy: 0.7396\n",
      "Epoch 1001/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4315 - accuracy: 0.7795 - val_loss: 0.5173 - val_accuracy: 0.7396\n",
      "Epoch 1002/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4315 - accuracy: 0.7795 - val_loss: 0.5174 - val_accuracy: 0.7396\n",
      "Epoch 1003/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4314 - accuracy: 0.7795 - val_loss: 0.5174 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1004/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4314 - accuracy: 0.7795 - val_loss: 0.5174 - val_accuracy: 0.7396\n",
      "Epoch 1005/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4313 - accuracy: 0.7795 - val_loss: 0.5174 - val_accuracy: 0.7396\n",
      "Epoch 1006/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4313 - accuracy: 0.7795 - val_loss: 0.5174 - val_accuracy: 0.7396\n",
      "Epoch 1007/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4313 - accuracy: 0.7795 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 1008/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4313 - accuracy: 0.7795 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 1009/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4312 - accuracy: 0.7795 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 1010/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4311 - accuracy: 0.7795 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 1011/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4311 - accuracy: 0.7795 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 1012/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4311 - accuracy: 0.7795 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 1013/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4311 - accuracy: 0.7795 - val_loss: 0.5175 - val_accuracy: 0.7344\n",
      "Epoch 1014/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4310 - accuracy: 0.7795 - val_loss: 0.5175 - val_accuracy: 0.7344\n",
      "Epoch 1015/1500\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4310 - accuracy: 0.7795 - val_loss: 0.5175 - val_accuracy: 0.7344\n",
      "Epoch 1016/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4309 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1017/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4309 - accuracy: 0.7795 - val_loss: 0.5175 - val_accuracy: 0.7344\n",
      "Epoch 1018/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4308 - accuracy: 0.7795 - val_loss: 0.5175 - val_accuracy: 0.7344\n",
      "Epoch 1019/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4308 - accuracy: 0.7795 - val_loss: 0.5175 - val_accuracy: 0.7344\n",
      "Epoch 1020/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4307 - accuracy: 0.7795 - val_loss: 0.5175 - val_accuracy: 0.7344\n",
      "Epoch 1021/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4307 - accuracy: 0.7795 - val_loss: 0.5175 - val_accuracy: 0.7344\n",
      "Epoch 1022/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4307 - accuracy: 0.7778 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1023/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4306 - accuracy: 0.7778 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1024/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4306 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1025/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4305 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1026/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4305 - accuracy: 0.7812 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1027/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4304 - accuracy: 0.7812 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1028/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4304 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1029/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4304 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1030/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4303 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1031/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4303 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1032/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4303 - accuracy: 0.7778 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1033/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4302 - accuracy: 0.7778 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1034/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4302 - accuracy: 0.7778 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1035/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4301 - accuracy: 0.7778 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1036/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4301 - accuracy: 0.7778 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1037/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4301 - accuracy: 0.7778 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1038/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4300 - accuracy: 0.7778 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1039/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4300 - accuracy: 0.7778 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1040/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4300 - accuracy: 0.7778 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1041/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4299 - accuracy: 0.7778 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1042/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4299 - accuracy: 0.7778 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1043/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4298 - accuracy: 0.7778 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1044/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4299 - accuracy: 0.7778 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1045/1500\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4298 - accuracy: 0.7778 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1046/1500\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4297 - accuracy: 0.7778 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1047/1500\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4297 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1048/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4297 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1049/1500\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4296 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1050/1500\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4296 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1051/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4295 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1052/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4295 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1053/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4295 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1054/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4294 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1055/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4294 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1056/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4294 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1057/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4293 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1058/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4293 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1059/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4293 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1060/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4293 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1061/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4292 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1062/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4292 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1063/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4291 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1064/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4291 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1065/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4290 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1066/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4290 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1067/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4290 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1068/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4290 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1069/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4289 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1070/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4289 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1071/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4288 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1072/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4289 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1073/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4287 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1074/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4287 - accuracy: 0.7778 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1075/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4287 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1076/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4287 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1077/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4286 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1078/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4286 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1079/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4286 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1080/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4285 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1081/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4285 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1082/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4285 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1083/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4284 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1084/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4284 - accuracy: 0.7795 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 1085/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4284 - accuracy: 0.7795 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 1086/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4283 - accuracy: 0.7795 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 1087/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4283 - accuracy: 0.7795 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 1088/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4283 - accuracy: 0.7795 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 1089/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4282 - accuracy: 0.7795 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 1090/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4282 - accuracy: 0.7795 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 1091/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4282 - accuracy: 0.7795 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 1092/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4282 - accuracy: 0.7795 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 1093/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4281 - accuracy: 0.7795 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 1094/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4280 - accuracy: 0.7795 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 1095/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4280 - accuracy: 0.7778 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 1096/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4280 - accuracy: 0.7778 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 1097/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4280 - accuracy: 0.7778 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 1098/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4279 - accuracy: 0.7778 - val_loss: 0.5178 - val_accuracy: 0.7344\n",
      "Epoch 1099/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4279 - accuracy: 0.7795 - val_loss: 0.5178 - val_accuracy: 0.7344\n",
      "Epoch 1100/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4278 - accuracy: 0.7795 - val_loss: 0.5178 - val_accuracy: 0.7344\n",
      "Epoch 1101/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4278 - accuracy: 0.7795 - val_loss: 0.5178 - val_accuracy: 0.7344\n",
      "Epoch 1102/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4278 - accuracy: 0.7795 - val_loss: 0.5178 - val_accuracy: 0.7344\n",
      "Epoch 1103/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4278 - accuracy: 0.7795 - val_loss: 0.5178 - val_accuracy: 0.7344\n",
      "Epoch 1104/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4277 - accuracy: 0.7795 - val_loss: 0.5178 - val_accuracy: 0.7344\n",
      "Epoch 1105/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4277 - accuracy: 0.7795 - val_loss: 0.5178 - val_accuracy: 0.7344\n",
      "Epoch 1106/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4276 - accuracy: 0.7778 - val_loss: 0.5178 - val_accuracy: 0.7344\n",
      "Epoch 1107/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4276 - accuracy: 0.7795 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 1108/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4276 - accuracy: 0.7778 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 1109/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4275 - accuracy: 0.7778 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 1110/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4275 - accuracy: 0.7778 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 1111/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4275 - accuracy: 0.7778 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 1112/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4274 - accuracy: 0.7778 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 1113/1500\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4274 - accuracy: 0.7778 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 1114/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 92us/step - loss: 0.4274 - accuracy: 0.7778 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 1115/1500\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4273 - accuracy: 0.7760 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1116/1500\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4273 - accuracy: 0.7778 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1117/1500\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.4273 - accuracy: 0.7760 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1118/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4273 - accuracy: 0.7778 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1119/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4272 - accuracy: 0.7760 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1120/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4271 - accuracy: 0.7778 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 1121/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4271 - accuracy: 0.7760 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 1122/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4271 - accuracy: 0.7778 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 1123/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4271 - accuracy: 0.7778 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 1124/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4270 - accuracy: 0.7778 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 1125/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4270 - accuracy: 0.7778 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 1126/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4270 - accuracy: 0.7795 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 1127/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4269 - accuracy: 0.7778 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 1128/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4269 - accuracy: 0.7760 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 1129/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4269 - accuracy: 0.7778 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 1130/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4268 - accuracy: 0.7760 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 1131/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4268 - accuracy: 0.7778 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 1132/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4268 - accuracy: 0.7778 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 1133/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4267 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 1134/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4267 - accuracy: 0.7778 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 1135/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4267 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 1136/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4266 - accuracy: 0.7778 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 1137/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4266 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 1138/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4266 - accuracy: 0.7778 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 1139/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4265 - accuracy: 0.7778 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 1140/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4265 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 1141/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4264 - accuracy: 0.7795 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 1142/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4264 - accuracy: 0.7795 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 1143/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4264 - accuracy: 0.7795 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 1144/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4264 - accuracy: 0.7778 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 1145/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4263 - accuracy: 0.7795 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 1146/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4263 - accuracy: 0.7795 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 1147/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4263 - accuracy: 0.7795 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
      "Epoch 1148/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4262 - accuracy: 0.7778 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
      "Epoch 1149/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4261 - accuracy: 0.7795 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
      "Epoch 1150/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4261 - accuracy: 0.7795 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
      "Epoch 1151/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4261 - accuracy: 0.7795 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
      "Epoch 1152/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4261 - accuracy: 0.7795 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
      "Epoch 1153/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4260 - accuracy: 0.7778 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
      "Epoch 1154/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4260 - accuracy: 0.7778 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
      "Epoch 1155/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4260 - accuracy: 0.7795 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
      "Epoch 1156/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4259 - accuracy: 0.7795 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
      "Epoch 1157/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4259 - accuracy: 0.7778 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
      "Epoch 1158/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4259 - accuracy: 0.7795 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1159/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4259 - accuracy: 0.7795 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1160/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4258 - accuracy: 0.7778 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1161/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4258 - accuracy: 0.7795 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1162/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4257 - accuracy: 0.7795 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1163/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4257 - accuracy: 0.7778 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1164/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4256 - accuracy: 0.7778 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1165/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4256 - accuracy: 0.7795 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1166/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4256 - accuracy: 0.7778 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1167/1500\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4255 - accuracy: 0.7795 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1168/1500\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4255 - accuracy: 0.7795 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1169/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4255 - accuracy: 0.7795 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1170/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4255 - accuracy: 0.7778 - val_loss: 0.5174 - val_accuracy: 0.7396\n",
      "Epoch 1171/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4254 - accuracy: 0.7778 - val_loss: 0.5174 - val_accuracy: 0.7396\n",
      "Epoch 1172/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4253 - accuracy: 0.7795 - val_loss: 0.5174 - val_accuracy: 0.7396\n",
      "Epoch 1173/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4253 - accuracy: 0.7778 - val_loss: 0.5174 - val_accuracy: 0.7396\n",
      "Epoch 1174/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4253 - accuracy: 0.7760 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 1175/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4253 - accuracy: 0.7760 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 1176/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4253 - accuracy: 0.7795 - val_loss: 0.5174 - val_accuracy: 0.7396\n",
      "Epoch 1177/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4252 - accuracy: 0.7795 - val_loss: 0.5174 - val_accuracy: 0.7396\n",
      "Epoch 1178/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4252 - accuracy: 0.7778 - val_loss: 0.5174 - val_accuracy: 0.7396\n",
      "Epoch 1179/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4251 - accuracy: 0.7760 - val_loss: 0.5174 - val_accuracy: 0.7396\n",
      "Epoch 1180/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4251 - accuracy: 0.7760 - val_loss: 0.5174 - val_accuracy: 0.7396\n",
      "Epoch 1181/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4251 - accuracy: 0.7760 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 1182/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4251 - accuracy: 0.7795 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 1183/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4250 - accuracy: 0.7760 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 1184/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4250 - accuracy: 0.7778 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 1185/1500\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4249 - accuracy: 0.7760 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 1186/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4249 - accuracy: 0.7760 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 1187/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4249 - accuracy: 0.7760 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 1188/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4249 - accuracy: 0.7760 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 1189/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4248 - accuracy: 0.7760 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 1190/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4248 - accuracy: 0.7760 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 1191/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4247 - accuracy: 0.7760 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 1192/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4247 - accuracy: 0.7778 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 1193/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4247 - accuracy: 0.7760 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 1194/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4246 - accuracy: 0.7760 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 1195/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4246 - accuracy: 0.7760 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 1196/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4245 - accuracy: 0.7760 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 1197/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4245 - accuracy: 0.7760 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 1198/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4244 - accuracy: 0.7760 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 1199/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4244 - accuracy: 0.7778 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 1200/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4244 - accuracy: 0.7760 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 1201/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4244 - accuracy: 0.7760 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 1202/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4243 - accuracy: 0.7778 - val_loss: 0.5177 - val_accuracy: 0.7396\n",
      "Epoch 1203/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4243 - accuracy: 0.7778 - val_loss: 0.5177 - val_accuracy: 0.7396\n",
      "Epoch 1204/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4242 - accuracy: 0.7760 - val_loss: 0.5177 - val_accuracy: 0.7396\n",
      "Epoch 1205/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4242 - accuracy: 0.7760 - val_loss: 0.5177 - val_accuracy: 0.7396\n",
      "Epoch 1206/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4242 - accuracy: 0.7760 - val_loss: 0.5177 - val_accuracy: 0.7396\n",
      "Epoch 1207/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4241 - accuracy: 0.7760 - val_loss: 0.5177 - val_accuracy: 0.7396\n",
      "Epoch 1208/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4241 - accuracy: 0.7778 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
      "Epoch 1209/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4241 - accuracy: 0.7760 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
      "Epoch 1210/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4240 - accuracy: 0.7778 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
      "Epoch 1211/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4240 - accuracy: 0.7778 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
      "Epoch 1212/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4239 - accuracy: 0.7778 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
      "Epoch 1213/1500\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4239 - accuracy: 0.7778 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
      "Epoch 1214/1500\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4239 - accuracy: 0.7778 - val_loss: 0.5179 - val_accuracy: 0.7448\n",
      "Epoch 1215/1500\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4239 - accuracy: 0.7778 - val_loss: 0.5179 - val_accuracy: 0.7448\n",
      "Epoch 1216/1500\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4238 - accuracy: 0.7778 - val_loss: 0.5179 - val_accuracy: 0.7448\n",
      "Epoch 1217/1500\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4238 - accuracy: 0.7778 - val_loss: 0.5179 - val_accuracy: 0.7448\n",
      "Epoch 1218/1500\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.4237 - accuracy: 0.7778 - val_loss: 0.5180 - val_accuracy: 0.7448\n",
      "Epoch 1219/1500\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4237 - accuracy: 0.7778 - val_loss: 0.5180 - val_accuracy: 0.7448\n",
      "Epoch 1220/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4236 - accuracy: 0.7778 - val_loss: 0.5180 - val_accuracy: 0.7448\n",
      "Epoch 1221/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4236 - accuracy: 0.7778 - val_loss: 0.5180 - val_accuracy: 0.7448\n",
      "Epoch 1222/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4236 - accuracy: 0.7778 - val_loss: 0.5181 - val_accuracy: 0.7448\n",
      "Epoch 1223/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4236 - accuracy: 0.7778 - val_loss: 0.5181 - val_accuracy: 0.7448\n",
      "Epoch 1224/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 40us/step - loss: 0.4235 - accuracy: 0.7778 - val_loss: 0.5180 - val_accuracy: 0.7448\n",
      "Epoch 1225/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4235 - accuracy: 0.7778 - val_loss: 0.5180 - val_accuracy: 0.7448\n",
      "Epoch 1226/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4234 - accuracy: 0.7795 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 1227/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4234 - accuracy: 0.7778 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 1228/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4233 - accuracy: 0.7795 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 1229/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4233 - accuracy: 0.7795 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 1230/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4233 - accuracy: 0.7795 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 1231/1500\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4233 - accuracy: 0.7795 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 1232/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4232 - accuracy: 0.7795 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 1233/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4232 - accuracy: 0.7795 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 1234/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4232 - accuracy: 0.7795 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 1235/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4231 - accuracy: 0.7795 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 1236/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4231 - accuracy: 0.7795 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 1237/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4829 - accuracy: 0.71 - 0s 43us/step - loss: 0.4231 - accuracy: 0.7795 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 1238/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4230 - accuracy: 0.7795 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 1239/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4230 - accuracy: 0.7812 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 1240/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4230 - accuracy: 0.7812 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 1241/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4229 - accuracy: 0.7812 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 1242/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4229 - accuracy: 0.7812 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 1243/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4228 - accuracy: 0.7812 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 1244/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4229 - accuracy: 0.7812 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 1245/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4228 - accuracy: 0.7812 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 1246/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4228 - accuracy: 0.7812 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 1247/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4228 - accuracy: 0.7812 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 1248/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4227 - accuracy: 0.7812 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 1249/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4226 - accuracy: 0.7795 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 1250/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4226 - accuracy: 0.7812 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 1251/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4226 - accuracy: 0.7795 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 1252/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4226 - accuracy: 0.7795 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 1253/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4226 - accuracy: 0.7795 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 1254/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4225 - accuracy: 0.7795 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 1255/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4225 - accuracy: 0.7795 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 1256/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4225 - accuracy: 0.7812 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 1257/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4224 - accuracy: 0.7795 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 1258/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4224 - accuracy: 0.7795 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 1259/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4224 - accuracy: 0.7795 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 1260/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4224 - accuracy: 0.7812 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 1261/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4223 - accuracy: 0.7812 - val_loss: 0.5187 - val_accuracy: 0.7448\n",
      "Epoch 1262/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4223 - accuracy: 0.7795 - val_loss: 0.5188 - val_accuracy: 0.7448\n",
      "Epoch 1263/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4223 - accuracy: 0.7795 - val_loss: 0.5188 - val_accuracy: 0.7448\n",
      "Epoch 1264/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4222 - accuracy: 0.7795 - val_loss: 0.5188 - val_accuracy: 0.7448\n",
      "Epoch 1265/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4222 - accuracy: 0.7812 - val_loss: 0.5188 - val_accuracy: 0.7448\n",
      "Epoch 1266/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4221 - accuracy: 0.7795 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
      "Epoch 1267/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4221 - accuracy: 0.7795 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
      "Epoch 1268/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4221 - accuracy: 0.7812 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 1269/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4221 - accuracy: 0.7812 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 1270/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4220 - accuracy: 0.7812 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 1271/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4220 - accuracy: 0.7812 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 1272/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4220 - accuracy: 0.7812 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 1273/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4219 - accuracy: 0.7812 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 1274/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4219 - accuracy: 0.7812 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
      "Epoch 1275/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4219 - accuracy: 0.7812 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
      "Epoch 1276/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4218 - accuracy: 0.7812 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
      "Epoch 1277/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4218 - accuracy: 0.7830 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
      "Epoch 1278/1500\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4218 - accuracy: 0.7830 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
      "Epoch 1279/1500\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4217 - accuracy: 0.7830 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
      "Epoch 1280/1500\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.4217 - accuracy: 0.7847 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
      "Epoch 1281/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4217 - accuracy: 0.7847 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
      "Epoch 1282/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4217 - accuracy: 0.7847 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 1283/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4216 - accuracy: 0.7847 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 1284/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4216 - accuracy: 0.7847 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 1285/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4216 - accuracy: 0.7847 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 1286/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4216 - accuracy: 0.7847 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
      "Epoch 1287/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4215 - accuracy: 0.7847 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
      "Epoch 1288/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4215 - accuracy: 0.7847 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
      "Epoch 1289/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4215 - accuracy: 0.7847 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
      "Epoch 1290/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4215 - accuracy: 0.7865 - val_loss: 0.5194 - val_accuracy: 0.7448\n",
      "Epoch 1291/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4214 - accuracy: 0.7847 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 1292/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4214 - accuracy: 0.7882 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 1293/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4214 - accuracy: 0.7847 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 1294/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4213 - accuracy: 0.7865 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 1295/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4213 - accuracy: 0.7847 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 1296/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4213 - accuracy: 0.7865 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 1297/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4212 - accuracy: 0.7882 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
      "Epoch 1298/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4212 - accuracy: 0.7847 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
      "Epoch 1299/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4212 - accuracy: 0.7882 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
      "Epoch 1300/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4211 - accuracy: 0.7865 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
      "Epoch 1301/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4211 - accuracy: 0.7882 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
      "Epoch 1302/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4210 - accuracy: 0.7882 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
      "Epoch 1303/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4210 - accuracy: 0.7847 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 1304/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4210 - accuracy: 0.7882 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 1305/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4210 - accuracy: 0.7865 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 1306/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4209 - accuracy: 0.7865 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 1307/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4209 - accuracy: 0.7882 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 1308/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4209 - accuracy: 0.7882 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 1309/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4209 - accuracy: 0.7882 - val_loss: 0.5198 - val_accuracy: 0.7344\n",
      "Epoch 1310/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4209 - accuracy: 0.7882 - val_loss: 0.5198 - val_accuracy: 0.7344\n",
      "Epoch 1311/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4208 - accuracy: 0.7882 - val_loss: 0.5198 - val_accuracy: 0.7344\n",
      "Epoch 1312/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4208 - accuracy: 0.7882 - val_loss: 0.5199 - val_accuracy: 0.7344\n",
      "Epoch 1313/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3356 - accuracy: 0.87 - 0s 43us/step - loss: 0.4208 - accuracy: 0.7882 - val_loss: 0.5199 - val_accuracy: 0.7344\n",
      "Epoch 1314/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4207 - accuracy: 0.7882 - val_loss: 0.5199 - val_accuracy: 0.7344\n",
      "Epoch 1315/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4207 - accuracy: 0.7882 - val_loss: 0.5199 - val_accuracy: 0.7344\n",
      "Epoch 1316/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4207 - accuracy: 0.7882 - val_loss: 0.5199 - val_accuracy: 0.7344\n",
      "Epoch 1317/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4207 - accuracy: 0.7882 - val_loss: 0.5199 - val_accuracy: 0.7344\n",
      "Epoch 1318/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4207 - accuracy: 0.7882 - val_loss: 0.5199 - val_accuracy: 0.7344\n",
      "Epoch 1319/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4206 - accuracy: 0.7882 - val_loss: 0.5199 - val_accuracy: 0.7344\n",
      "Epoch 1320/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4206 - accuracy: 0.7882 - val_loss: 0.5199 - val_accuracy: 0.7344\n",
      "Epoch 1321/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4206 - accuracy: 0.7882 - val_loss: 0.5199 - val_accuracy: 0.7344\n",
      "Epoch 1322/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4205 - accuracy: 0.7882 - val_loss: 0.5199 - val_accuracy: 0.7344\n",
      "Epoch 1323/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4205 - accuracy: 0.7882 - val_loss: 0.5199 - val_accuracy: 0.7344\n",
      "Epoch 1324/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4205 - accuracy: 0.7882 - val_loss: 0.5198 - val_accuracy: 0.7344\n",
      "Epoch 1325/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4205 - accuracy: 0.7882 - val_loss: 0.5198 - val_accuracy: 0.7344\n",
      "Epoch 1326/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4204 - accuracy: 0.7882 - val_loss: 0.5198 - val_accuracy: 0.7344\n",
      "Epoch 1327/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4204 - accuracy: 0.7882 - val_loss: 0.5198 - val_accuracy: 0.7344\n",
      "Epoch 1328/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4203 - accuracy: 0.7882 - val_loss: 0.5198 - val_accuracy: 0.7344\n",
      "Epoch 1329/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4204 - accuracy: 0.7882 - val_loss: 0.5198 - val_accuracy: 0.7344\n",
      "Epoch 1330/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4203 - accuracy: 0.7882 - val_loss: 0.5198 - val_accuracy: 0.7344\n",
      "Epoch 1331/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4203 - accuracy: 0.7882 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 1332/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4203 - accuracy: 0.7882 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 1333/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4202 - accuracy: 0.7882 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 1334/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 43us/step - loss: 0.4202 - accuracy: 0.7882 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 1335/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4202 - accuracy: 0.7882 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 1336/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4202 - accuracy: 0.7882 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
      "Epoch 1337/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4201 - accuracy: 0.7882 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
      "Epoch 1338/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4201 - accuracy: 0.7882 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
      "Epoch 1339/1500\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.4201 - accuracy: 0.7882 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
      "Epoch 1340/1500\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4201 - accuracy: 0.7882 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
      "Epoch 1341/1500\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4200 - accuracy: 0.7882 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
      "Epoch 1342/1500\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4200 - accuracy: 0.7882 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
      "Epoch 1343/1500\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4200 - accuracy: 0.7882 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
      "Epoch 1344/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4200 - accuracy: 0.7882 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
      "Epoch 1345/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4199 - accuracy: 0.7882 - val_loss: 0.5196 - val_accuracy: 0.7292\n",
      "Epoch 1346/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4199 - accuracy: 0.7882 - val_loss: 0.5196 - val_accuracy: 0.7292\n",
      "Epoch 1347/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4199 - accuracy: 0.7882 - val_loss: 0.5196 - val_accuracy: 0.7292\n",
      "Epoch 1348/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4199 - accuracy: 0.7882 - val_loss: 0.5195 - val_accuracy: 0.7292\n",
      "Epoch 1349/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4198 - accuracy: 0.7882 - val_loss: 0.5195 - val_accuracy: 0.7292\n",
      "Epoch 1350/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4199 - accuracy: 0.7882 - val_loss: 0.5195 - val_accuracy: 0.7292\n",
      "Epoch 1351/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4198 - accuracy: 0.7882 - val_loss: 0.5195 - val_accuracy: 0.7292\n",
      "Epoch 1352/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4198 - accuracy: 0.7882 - val_loss: 0.5195 - val_accuracy: 0.7292\n",
      "Epoch 1353/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4197 - accuracy: 0.7882 - val_loss: 0.5195 - val_accuracy: 0.7292\n",
      "Epoch 1354/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4197 - accuracy: 0.7882 - val_loss: 0.5195 - val_accuracy: 0.7292\n",
      "Epoch 1355/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4197 - accuracy: 0.7882 - val_loss: 0.5194 - val_accuracy: 0.7292\n",
      "Epoch 1356/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4196 - accuracy: 0.7882 - val_loss: 0.5194 - val_accuracy: 0.7292\n",
      "Epoch 1357/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4197 - accuracy: 0.7882 - val_loss: 0.5194 - val_accuracy: 0.7292\n",
      "Epoch 1358/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4196 - accuracy: 0.7882 - val_loss: 0.5195 - val_accuracy: 0.7292\n",
      "Epoch 1359/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4196 - accuracy: 0.7882 - val_loss: 0.5195 - val_accuracy: 0.7292\n",
      "Epoch 1360/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4196 - accuracy: 0.7882 - val_loss: 0.5194 - val_accuracy: 0.7292\n",
      "Epoch 1361/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4195 - accuracy: 0.7882 - val_loss: 0.5195 - val_accuracy: 0.7292\n",
      "Epoch 1362/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4195 - accuracy: 0.7882 - val_loss: 0.5195 - val_accuracy: 0.7292\n",
      "Epoch 1363/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4195 - accuracy: 0.7882 - val_loss: 0.5194 - val_accuracy: 0.7292\n",
      "Epoch 1364/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4195 - accuracy: 0.7882 - val_loss: 0.5194 - val_accuracy: 0.7292\n",
      "Epoch 1365/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4194 - accuracy: 0.7882 - val_loss: 0.5194 - val_accuracy: 0.7292\n",
      "Epoch 1366/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4194 - accuracy: 0.7882 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
      "Epoch 1367/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4194 - accuracy: 0.7882 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
      "Epoch 1368/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4194 - accuracy: 0.7882 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
      "Epoch 1369/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4193 - accuracy: 0.7882 - val_loss: 0.5193 - val_accuracy: 0.7344\n",
      "Epoch 1370/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4193 - accuracy: 0.7882 - val_loss: 0.5193 - val_accuracy: 0.7344\n",
      "Epoch 1371/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4193 - accuracy: 0.7882 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
      "Epoch 1372/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4193 - accuracy: 0.7882 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
      "Epoch 1373/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4192 - accuracy: 0.7882 - val_loss: 0.5193 - val_accuracy: 0.7344\n",
      "Epoch 1374/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4192 - accuracy: 0.7882 - val_loss: 0.5193 - val_accuracy: 0.7344\n",
      "Epoch 1375/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4192 - accuracy: 0.7882 - val_loss: 0.5193 - val_accuracy: 0.7344\n",
      "Epoch 1376/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4191 - accuracy: 0.7882 - val_loss: 0.5193 - val_accuracy: 0.7344\n",
      "Epoch 1377/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4192 - accuracy: 0.7899 - val_loss: 0.5193 - val_accuracy: 0.7344\n",
      "Epoch 1378/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4191 - accuracy: 0.7899 - val_loss: 0.5193 - val_accuracy: 0.7344\n",
      "Epoch 1379/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4191 - accuracy: 0.7882 - val_loss: 0.5192 - val_accuracy: 0.7344\n",
      "Epoch 1380/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4191 - accuracy: 0.7899 - val_loss: 0.5193 - val_accuracy: 0.7344\n",
      "Epoch 1381/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4190 - accuracy: 0.7882 - val_loss: 0.5193 - val_accuracy: 0.7344\n",
      "Epoch 1382/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4190 - accuracy: 0.7882 - val_loss: 0.5192 - val_accuracy: 0.7344\n",
      "Epoch 1383/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4190 - accuracy: 0.7882 - val_loss: 0.5192 - val_accuracy: 0.7344\n",
      "Epoch 1384/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4190 - accuracy: 0.7899 - val_loss: 0.5192 - val_accuracy: 0.7344\n",
      "Epoch 1385/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4190 - accuracy: 0.7882 - val_loss: 0.5192 - val_accuracy: 0.7344\n",
      "Epoch 1386/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4189 - accuracy: 0.7882 - val_loss: 0.5191 - val_accuracy: 0.7344\n",
      "Epoch 1387/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4189 - accuracy: 0.7899 - val_loss: 0.5191 - val_accuracy: 0.7344\n",
      "Epoch 1388/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4189 - accuracy: 0.7899 - val_loss: 0.5191 - val_accuracy: 0.7344\n",
      "Epoch 1389/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4189 - accuracy: 0.7899 - val_loss: 0.5191 - val_accuracy: 0.7344\n",
      "Epoch 1390/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4188 - accuracy: 0.7899 - val_loss: 0.5191 - val_accuracy: 0.7344\n",
      "Epoch 1391/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4188 - accuracy: 0.7899 - val_loss: 0.5191 - val_accuracy: 0.7344\n",
      "Epoch 1392/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4188 - accuracy: 0.7899 - val_loss: 0.5191 - val_accuracy: 0.7344\n",
      "Epoch 1393/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4188 - accuracy: 0.7899 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 1394/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4188 - accuracy: 0.7899 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 1395/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4187 - accuracy: 0.7899 - val_loss: 0.5191 - val_accuracy: 0.7344\n",
      "Epoch 1396/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4187 - accuracy: 0.7899 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 1397/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4186 - accuracy: 0.7899 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 1398/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4186 - accuracy: 0.7899 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 1399/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4187 - accuracy: 0.7899 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 1400/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4186 - accuracy: 0.7899 - val_loss: 0.5191 - val_accuracy: 0.7344\n",
      "Epoch 1401/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4186 - accuracy: 0.7917 - val_loss: 0.5191 - val_accuracy: 0.7344\n",
      "Epoch 1402/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4186 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 1403/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4186 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 1404/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4185 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 1405/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4185 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 1406/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4185 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 1407/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4185 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 1408/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4185 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 1409/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4185 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 1410/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4184 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 1411/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4184 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 1412/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4184 - accuracy: 0.7917 - val_loss: 0.5191 - val_accuracy: 0.7344\n",
      "Epoch 1413/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4184 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 1414/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4183 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 1415/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4183 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 1416/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4183 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 1417/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4183 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 1418/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4182 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 1419/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4182 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 1420/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4182 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 1421/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4182 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 1422/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4182 - accuracy: 0.7917 - val_loss: 0.5189 - val_accuracy: 0.7396\n",
      "Epoch 1423/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4182 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 1424/1500\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4181 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 1425/1500\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4181 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 1426/1500\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4181 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 1427/1500\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4181 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 1428/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4181 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 1429/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4181 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 1430/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4180 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 1431/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4180 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 1432/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4180 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 1433/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4180 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 1434/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4180 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 1435/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4179 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 1436/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4179 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 1437/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4179 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 1438/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4179 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 1439/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4179 - accuracy: 0.7934 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 1440/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4179 - accuracy: 0.7917 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 1441/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4178 - accuracy: 0.7934 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 1442/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4178 - accuracy: 0.7917 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 1443/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4178 - accuracy: 0.7934 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 1444/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 47us/step - loss: 0.4178 - accuracy: 0.7934 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 1445/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4178 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 1446/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4177 - accuracy: 0.7934 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 1447/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4177 - accuracy: 0.7934 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 1448/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4177 - accuracy: 0.7934 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 1449/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4177 - accuracy: 0.7951 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 1450/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4177 - accuracy: 0.7934 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 1451/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4177 - accuracy: 0.7934 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 1452/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4177 - accuracy: 0.7934 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 1453/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4176 - accuracy: 0.7934 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 1454/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4176 - accuracy: 0.7934 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 1455/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4176 - accuracy: 0.7934 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 1456/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4176 - accuracy: 0.7917 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 1457/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4176 - accuracy: 0.7951 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 1458/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4176 - accuracy: 0.7934 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 1459/1500\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4175 - accuracy: 0.7934 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 1460/1500\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4175 - accuracy: 0.7934 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 1461/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4175 - accuracy: 0.7934 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 1462/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4175 - accuracy: 0.7934 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 1463/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4175 - accuracy: 0.7934 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 1464/1500\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4175 - accuracy: 0.7934 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
      "Epoch 1465/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4175 - accuracy: 0.7934 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
      "Epoch 1466/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4175 - accuracy: 0.7934 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
      "Epoch 1467/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4174 - accuracy: 0.7934 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
      "Epoch 1468/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4174 - accuracy: 0.7951 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
      "Epoch 1469/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4174 - accuracy: 0.7951 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
      "Epoch 1470/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4174 - accuracy: 0.7951 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 1471/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4173 - accuracy: 0.7934 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 1472/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4174 - accuracy: 0.7951 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 1473/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4173 - accuracy: 0.7951 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 1474/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4173 - accuracy: 0.7951 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 1475/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4173 - accuracy: 0.7934 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 1476/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4173 - accuracy: 0.7934 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 1477/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4173 - accuracy: 0.7951 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 1478/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4172 - accuracy: 0.7951 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 1479/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4172 - accuracy: 0.7951 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 1480/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4172 - accuracy: 0.7951 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 1481/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4172 - accuracy: 0.7951 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 1482/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4172 - accuracy: 0.7951 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 1483/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4171 - accuracy: 0.7951 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 1484/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4171 - accuracy: 0.7934 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 1485/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4171 - accuracy: 0.7951 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 1486/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4171 - accuracy: 0.7951 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 1487/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4171 - accuracy: 0.7951 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 1488/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4171 - accuracy: 0.7951 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 1489/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4171 - accuracy: 0.7934 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 1490/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4170 - accuracy: 0.7951 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 1491/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4170 - accuracy: 0.7934 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 1492/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4170 - accuracy: 0.7951 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 1493/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4170 - accuracy: 0.7951 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 1494/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4170 - accuracy: 0.7951 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 1495/1500\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4170 - accuracy: 0.7951 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 1496/1500\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4170 - accuracy: 0.7951 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 1497/1500\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4169 - accuracy: 0.7951 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 1498/1500\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4169 - accuracy: 0.7934 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 1499/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4169 - accuracy: 0.7934 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 1500/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4169 - accuracy: 0.7951 - val_loss: 0.5195 - val_accuracy: 0.7396\n"
     ]
    }
   ],
   "source": [
    "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class_nn_2 = model_2.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_2 = model_2.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_class_nn_2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5637711 ],\n",
       "       [0.6896335 ],\n",
       "       [0.41170442],\n",
       "       [0.31653708],\n",
       "       [0.11956972],\n",
       "       [0.6098838 ],\n",
       "       [0.01099312],\n",
       "       [0.25649643],\n",
       "       [0.86604106],\n",
       "       [0.17570454]], dtype=float32)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.734\n",
      "roc-auc is 0.807\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_2, 'NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_2.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29e1bc2a128>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_2.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_2.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4154 - accuracy: 0.7951 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4153 - accuracy: 0.7969 - val_loss: 0.5195 - val_accuracy: 0.7344\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4153 - accuracy: 0.7969 - val_loss: 0.5195 - val_accuracy: 0.7344\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4153 - accuracy: 0.7951 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4153 - accuracy: 0.7951 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4153 - accuracy: 0.7934 - val_loss: 0.5193 - val_accuracy: 0.7344\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4152 - accuracy: 0.7951 - val_loss: 0.5193 - val_accuracy: 0.7344\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4152 - accuracy: 0.7934 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4152 - accuracy: 0.7951 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.4152 - accuracy: 0.7951 - val_loss: 0.5193 - val_accuracy: 0.7344\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4152 - accuracy: 0.7951 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 0.4152 - accuracy: 0.7951 - val_loss: 0.5193 - val_accuracy: 0.7344\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4152 - accuracy: 0.7934 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4151 - accuracy: 0.7934 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4151 - accuracy: 0.7951 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4151 - accuracy: 0.7951 - val_loss: 0.5193 - val_accuracy: 0.7344\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4151 - accuracy: 0.7951 - val_loss: 0.5193 - val_accuracy: 0.7344\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4151 - accuracy: 0.7951 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4150 - accuracy: 0.7951 - val_loss: 0.5193 - val_accuracy: 0.7344\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4150 - accuracy: 0.7951 - val_loss: 0.5193 - val_accuracy: 0.7344\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4150 - accuracy: 0.7951 - val_loss: 0.5192 - val_accuracy: 0.7344\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4150 - accuracy: 0.7951 - val_loss: 0.5192 - val_accuracy: 0.7344\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4149 - accuracy: 0.7951 - val_loss: 0.5192 - val_accuracy: 0.7344\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4149 - accuracy: 0.7951 - val_loss: 0.5191 - val_accuracy: 0.7344\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4149 - accuracy: 0.7934 - val_loss: 0.5191 - val_accuracy: 0.7344\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4149 - accuracy: 0.7951 - val_loss: 0.5191 - val_accuracy: 0.7344\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4149 - accuracy: 0.7934 - val_loss: 0.5191 - val_accuracy: 0.7344\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4149 - accuracy: 0.7951 - val_loss: 0.5192 - val_accuracy: 0.7344\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4148 - accuracy: 0.7934 - val_loss: 0.5191 - val_accuracy: 0.7344\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4149 - accuracy: 0.7934 - val_loss: 0.5191 - val_accuracy: 0.7344\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4148 - accuracy: 0.7934 - val_loss: 0.5191 - val_accuracy: 0.7344\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4148 - accuracy: 0.7951 - val_loss: 0.5191 - val_accuracy: 0.7344\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4147 - accuracy: 0.7951 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4148 - accuracy: 0.7934 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4147 - accuracy: 0.7934 - val_loss: 0.5189 - val_accuracy: 0.7344\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4147 - accuracy: 0.7934 - val_loss: 0.5189 - val_accuracy: 0.7344\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4147 - accuracy: 0.7951 - val_loss: 0.5189 - val_accuracy: 0.7344\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4147 - accuracy: 0.7951 - val_loss: 0.5189 - val_accuracy: 0.7344\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4147 - accuracy: 0.7951 - val_loss: 0.5188 - val_accuracy: 0.7344\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4146 - accuracy: 0.7934 - val_loss: 0.5188 - val_accuracy: 0.7344\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4146 - accuracy: 0.7934 - val_loss: 0.5188 - val_accuracy: 0.7344\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4146 - accuracy: 0.7934 - val_loss: 0.5188 - val_accuracy: 0.7344\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4146 - accuracy: 0.7934 - val_loss: 0.5188 - val_accuracy: 0.7344\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4146 - accuracy: 0.7934 - val_loss: 0.5188 - val_accuracy: 0.7344\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4145 - accuracy: 0.7951 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4145 - accuracy: 0.7934 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4145 - accuracy: 0.7934 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4145 - accuracy: 0.7934 - val_loss: 0.5185 - val_accuracy: 0.7396\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4144 - accuracy: 0.7934 - val_loss: 0.5185 - val_accuracy: 0.7396\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4144 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7396\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4144 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7396\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4144 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7396\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4143 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7396\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4143 - accuracy: 0.7951 - val_loss: 0.5183 - val_accuracy: 0.7396\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4143 - accuracy: 0.7951 - val_loss: 0.5183 - val_accuracy: 0.7396\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4143 - accuracy: 0.7934 - val_loss: 0.5183 - val_accuracy: 0.7396\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4143 - accuracy: 0.7934 - val_loss: 0.5182 - val_accuracy: 0.7396\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4142 - accuracy: 0.7934 - val_loss: 0.5182 - val_accuracy: 0.7396\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4855 - accuracy: 0.68 - 0s 36us/step - loss: 0.4143 - accuracy: 0.7951 - val_loss: 0.5181 - val_accuracy: 0.7396\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4142 - accuracy: 0.7951 - val_loss: 0.5181 - val_accuracy: 0.7396\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4141 - accuracy: 0.7951 - val_loss: 0.5181 - val_accuracy: 0.7396\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4141 - accuracy: 0.7951 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4141 - accuracy: 0.7951 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4142 - accuracy: 0.7951 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4141 - accuracy: 0.7951 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4140 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4140 - accuracy: 0.7969 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4140 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4139 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4139 - accuracy: 0.7969 - val_loss: 0.5178 - val_accuracy: 0.7396\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4139 - accuracy: 0.7969 - val_loss: 0.5178 - val_accuracy: 0.7396\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4139 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7396\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.4139 - accuracy: 0.7951 - val_loss: 0.5177 - val_accuracy: 0.7396\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4139 - accuracy: 0.7969 - val_loss: 0.5177 - val_accuracy: 0.7396\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4138 - accuracy: 0.7969 - val_loss: 0.5178 - val_accuracy: 0.7396\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4138 - accuracy: 0.7969 - val_loss: 0.5177 - val_accuracy: 0.7448\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4138 - accuracy: 0.7969 - val_loss: 0.5177 - val_accuracy: 0.7448\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4137 - accuracy: 0.7969 - val_loss: 0.5177 - val_accuracy: 0.7448\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4137 - accuracy: 0.7969 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4138 - accuracy: 0.7969 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4137 - accuracy: 0.7969 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4137 - accuracy: 0.7969 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4136 - accuracy: 0.7969 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4764 - accuracy: 0.71 - 0s 42us/step - loss: 0.4136 - accuracy: 0.7969 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4136 - accuracy: 0.7969 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4136 - accuracy: 0.7969 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4135 - accuracy: 0.7969 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4135 - accuracy: 0.7969 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4135 - accuracy: 0.7986 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4135 - accuracy: 0.7986 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4135 - accuracy: 0.7986 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4135 - accuracy: 0.7986 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4135 - accuracy: 0.7969 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4134 - accuracy: 0.7986 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4134 - accuracy: 0.7986 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4134 - accuracy: 0.7969 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4134 - accuracy: 0.7986 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4134 - accuracy: 0.7986 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4133 - accuracy: 0.7986 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4133 - accuracy: 0.7986 - val_loss: 0.5173 - val_accuracy: 0.7448\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_2b = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29e17e7ddd8>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_2.history[\"loss\"])\n",
    "m = len(run_hist_2b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_2.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_2b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_2.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_2b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
